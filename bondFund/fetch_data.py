import akshare as ak
import pandas as pd
from scipy import stats
import datetime
import numpy as np
import warnings
import ssl
import os
import json
import requests
import urllib3

# ==========================================
# âš™ï¸ é…ç½®å¸¸é‡
# ==========================================
class Config:
    """é‡åŒ–ç­–ç•¥é…ç½®å‚æ•°"""
    # æ•°æ®æ—¶é—´èŒƒå›´
    DATA_YEARS = 10  # å†å²æ•°æ®å¹´æ•°
    
    # æŠ€æœ¯æŒ‡æ ‡å‚æ•°
    MA_PERIOD = 60  # å‡çº¿å‘¨æœŸ
    MACD_FAST = 12  # MACD å¿«çº¿
    MACD_SLOW = 26  # MACD æ…¢çº¿
    MACD_SIGNAL = 9  # MACD ä¿¡å·çº¿
    RSI_PERIOD = 14  # RSI å‘¨æœŸ
    BB_PERIOD = 20  # å¸ƒæ—å¸¦å‘¨æœŸ
    BB_STD = 2  # å¸ƒæ—å¸¦æ ‡å‡†å·®å€æ•°
    
    # è¯„åˆ†é˜ˆå€¼
    PERCENTILE_CHEAP = 80  # ä¾¿å®œé˜ˆå€¼
    PERCENTILE_EXPENSIVE = 20  # æ˜‚è´µé˜ˆå€¼
    RSI_OVERSOLD = 30  # RSI è¶…å–
    RSI_OVERBOUGHT = 70  # RSI è¶…ä¹°
    
    # æµåŠ¨æ€§å˜åŒ–é˜ˆå€¼ï¼ˆçœ‹è¶‹åŠ¿ï¼Œä¸çœ‹ç»å¯¹å€¼ï¼‰
    # Shiborä¸Šå‡ â†’ èµ„é‡‘æ”¶ç´§ â†’ åˆ©ç©ºå€ºå¸‚
    # Shiborä¸‹é™ â†’ èµ„é‡‘å®½æ¾ â†’ åˆ©å¥½å€ºå¸‚
    SHIBOR_LOOKBACK = 20  # å›çœ‹å¤©æ•°ï¼ˆçº¦1ä¸ªæœˆï¼‰
    SHIBOR_MAX_CHANGE = 0.5  # Shiborå˜åŒ–è¶…è¿‡50bpè§†ä¸ºæç«¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
    
    # ERP é˜ˆå€¼ï¼ˆç”¨äºè¿ç»­è¯„åˆ†ï¼‰
    ERP_NEUTRAL = 3.75  # ERPä¸­æ€§å€¼ï¼ˆè‚¡å€ºå¹³è¡¡ç‚¹ï¼‰
    ERP_MAX_DEVIATION = 1.75  # æœ€å¤§åç¦»ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼Œå³2.0-5.5èŒƒå›´ï¼‰
    
    # ä¸­ç¾åˆ©å·®å˜åŒ–é˜ˆå€¼ï¼ˆçœ‹è¶‹åŠ¿ï¼Œä¸çœ‹ç»å¯¹å€¼ï¼‰
    # åˆ©å·®æ”¶çª„ï¼ˆå˜å¥½ï¼‰â†’ é™æ¯ç©ºé—´å˜å¤§ â†’ åˆ©å¥½å€ºå¸‚
    # åˆ©å·®èµ°é˜”ï¼ˆå˜å·®ï¼‰â†’ é™æ¯ç©ºé—´å˜å° â†’ åˆ©ç©ºå€ºå¸‚
    SPREAD_LOOKBACK = 60  # å›çœ‹å¤©æ•°ï¼ˆçº¦3ä¸ªæœˆï¼‰
    SPREAD_MAX_CHANGE = 0.5  # åˆ©å·®å˜åŒ–è¶…è¿‡50bpè§†ä¸ºæç«¯ï¼ˆç”¨äºå½’ä¸€åŒ–ï¼‰
    
    # è¯„åˆ†æƒé‡
    SCORE_BASE = 50
    SCORE_PERCENTILE_WEIGHT = 0.6  # ä¼°å€¼æƒé‡æé«˜ï¼Œè®©è¯„åˆ†æ›´æœ‰åŒºåˆ†åº¦
    SCORE_TREND_BONUS = 8   # è¶‹åŠ¿æƒé‡ï¼ˆéœ‡è¡å¸‚åœºæ—¶ä½¿ç”¨ï¼‰
    SCORE_RSI_BONUS = 6     # RSI æƒé‡ï¼ˆéœ‡è¡å¸‚åœºæ—¶ä½¿ç”¨ï¼‰
    SCORE_LIQUIDITY_PENALTY = 8
    SCORE_MACRO_PENALTY = 10
    
    # å¸‚åœºçŠ¶æ€åˆ¤æ–­å‚æ•°
    TREND_CONSECUTIVE_DAYS = 40  # è¿ç»­Nå¤©åœ¨MAåŒä¸€ä¾§è§†ä¸ºå•è¾¹å¸‚åœº
    MA_CROSS_LOOKBACK = 120      # å›çœ‹å¤©æ•°ï¼Œç”¨äºè®¡ç®—ç©¿è¶Šé¢‘ç‡
    
    # å¤©æ°”è¯„åˆ†åŒºé—´
    WEATHER_SUNNY = 80
    WEATHER_CLEAR = 60
    WEATHER_CLOUDY = 40
    WEATHER_RAINY = 20

# ==========================================
# ğŸ›¡ï¸ ç³»ç»Ÿåº•å±‚é…ç½®
# ==========================================
warnings.filterwarnings("ignore")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ã€ä¼˜åŒ–ã€‘ä¸å†å…¨å±€ patch SSL å’Œ requests
# æ”¹ä¸ºåœ¨éœ€è¦æ—¶åˆ›å»ºä¸“ç”¨ sessionï¼Œé¿å…å½±å“å…¶ä»–åº“
def create_akshare_session():
    """åˆ›å»ºç”¨äº akshare çš„ä¸“ç”¨ sessionï¼Œç¦ç”¨ SSL éªŒè¯"""
    session = requests.Session()
    session.verify = False
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    return session

# ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼ˆä»…ç”¨äº akshare è°ƒç”¨ï¼‰
# æ³¨æ„ï¼šè¿™æ˜¯ä¸ºäº†å…¼å®¹æŸäº›ç½‘ç»œç¯å¢ƒï¼Œç”Ÿäº§ç¯å¢ƒåº”é…ç½®æ­£ç¡®çš„è¯ä¹¦
import contextlib

@contextlib.contextmanager
def disable_ssl_verification():
    """ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
    old_request = requests.Session.request
    def patched_request(self, method, url, *args, **kwargs):
        kwargs['verify'] = False
        if 'headers' not in kwargs:
            kwargs['headers'] = {}
        kwargs['headers'].update({
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        })
        return old_request(self, method, url, *args, **kwargs)
    
    requests.Session.request = patched_request
    try:
        yield
    finally:
        requests.Session.request = old_request

# ==========================================
# ğŸ§  æ ¸å¿ƒè®¡ç®—å¼•æ“
# ==========================================

def calculate_technical_indicators(df):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
    
    æ³¨æ„ï¼šMACD ç›¸å…³æŒ‡æ ‡ï¼ˆMACD, Signal_Line, MACD_Histï¼‰ä»…ç”¨äºå±•ç¤ºå’Œè¶‹åŠ¿è§£é‡Šï¼Œ
    ä¸å‚ä¸è¯„åˆ†è®¡ç®—ã€‚è¯„åˆ†ä¸»è¦ä¾èµ–ä¼°å€¼ï¼ˆåˆ†ä½æ•°ï¼‰å’Œè¶‹åŠ¿ï¼ˆMA60åç¦»ï¼‰ã€‚
    """
    df['MA60'] = df['yield'].rolling(window=Config.MA_PERIOD).mean()
    
    # MACD æŒ‡æ ‡ï¼ˆä»…ç”¨äºå±•ç¤ºï¼Œä¸å‚ä¸è¯„åˆ†ï¼‰
    exp1 = df['yield'].ewm(span=Config.MACD_FAST, adjust=False).mean()
    exp2 = df['yield'].ewm(span=Config.MACD_SLOW, adjust=False).mean()
    df['MACD'] = exp1 - exp2
    df['Signal_Line'] = df['MACD'].ewm(span=Config.MACD_SIGNAL, adjust=False).mean()
    df['MACD_Hist'] = df['MACD'] - df['Signal_Line']
    
    delta = df['yield'].diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=Config.RSI_PERIOD).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=Config.RSI_PERIOD).mean()
    rs = gain / loss
    df['RSI'] = 100 - (100 / (1 + rs))
    
    df['BB_Mid'] = df['yield'].rolling(window=Config.BB_PERIOD).mean()
    df['BB_Std'] = df['yield'].rolling(window=Config.BB_PERIOD).std()
    df['BB_Up'] = df['BB_Mid'] + Config.BB_STD * df['BB_Std']
    df['BB_Low'] = df['BB_Mid'] - Config.BB_STD * df['BB_Std']
    return df

def detect_market_regime(df: pd.DataFrame, current_idx: int = -1) -> dict:
    """
    æ£€æµ‹å½“å‰å¸‚åœºçŠ¶æ€ï¼šæŒç»­åç¦» vs å‡å€¼å›å½’
    
    æ–¹æ³•ï¼šè®¡ç®—æ”¶ç›Šç‡åœ¨MA60åŒä¸€ä¾§çš„è¿ç»­å¤©æ•°
    - è¿ç»­å¤©æ•° >= TREND_CONSECUTIVE_DAYS â†’ æŒç»­åç¦»ï¼ˆextendedï¼‰
    - è¿ç»­å¤©æ•° < TREND_CONSECUTIVE_DAYS â†’ å‡å€¼å›å½’ï¼ˆmean-revertingï¼‰
    
    ã€ä¼˜åŒ–ã€‘å‘½åæ›´å‡†ç¡®ï¼š
    - "extended": æ”¶ç›Šç‡æŒç»­åç¦»å‡çº¿ï¼Œè¶‹åŠ¿å¯èƒ½å»¶ç»­
    - "mean-reverting": æ”¶ç›Šç‡åœ¨å‡çº¿é™„è¿‘éœ‡è¡ï¼Œæ›´å¯èƒ½å›å½’
    
    è¿”å›ï¼š
    - regime: "extended" (æŒç»­åç¦») æˆ– "mean-reverting" (å‡å€¼å›å½’)
    - consecutive_days: è¿ç»­å¤©æ•°
    - trend_weight: è¶‹åŠ¿å› å­æƒé‡ (0-1)
    - direction: "bull" (ç‰›å¸‚ï¼Œæ”¶ç›Šç‡<MA) æˆ– "bear" (ç†Šå¸‚ï¼Œæ”¶ç›Šç‡>MA)
    """
    if len(df) < Config.MA_PERIOD:
        return {"regime": "unknown", "consecutive_days": 0, "trend_weight": 0.5, "direction": None}
    
    # è·å–åˆ°å½“å‰ä½ç½®çš„æ•°æ®
    if current_idx == -1:
        current_idx = len(df) - 1
    
    # è®¡ç®—æ”¶ç›Šç‡ä¸MA60çš„å…³ç³»
    yield_col = df['yield'].values
    ma60_col = df['MA60'].values
    
    # ä»å½“å‰ä½ç½®å¾€å›æ•°ï¼Œçœ‹è¿ç»­å¤šå°‘å¤©åœ¨MAåŒä¸€ä¾§
    consecutive_days = 0
    current_above_ma = yield_col[current_idx] > ma60_col[current_idx]
    
    for i in range(current_idx, max(0, current_idx - Config.MA_CROSS_LOOKBACK), -1):
        if pd.isna(ma60_col[i]):
            break
        is_above = yield_col[i] > ma60_col[i]
        if is_above == current_above_ma:
            consecutive_days += 1
        else:
            break
    
    # åˆ¤æ–­å¸‚åœºçŠ¶æ€
    if consecutive_days >= Config.TREND_CONSECUTIVE_DAYS:
        regime = "extended"  # æŒç»­åç¦»
        # æŒç»­åç¦»ï¼šè¶‹åŠ¿å› å­æƒé‡é™ä½ï¼Œè¿ç»­å¤©æ•°è¶Šé•¿æƒé‡è¶Šä½
        # ä»1.0çº¿æ€§é™åˆ°0ï¼Œè¶…è¿‡2å€é˜ˆå€¼åå®Œå…¨ä¸º0
        weight_decay = min(1.0, (consecutive_days - Config.TREND_CONSECUTIVE_DAYS) / Config.TREND_CONSECUTIVE_DAYS)
        trend_weight = max(0, 1.0 - weight_decay)
    else:
        regime = "mean-reverting"  # å‡å€¼å›å½’
        # å‡å€¼å›å½’ï¼šè¶‹åŠ¿å› å­æƒé‡æ­£å¸¸
        # è¿ç»­å¤©æ•°è¶Šå°‘ï¼Œæƒé‡è¶Šé«˜ï¼ˆè¯´æ˜å¸‚åœºè¶Šéœ‡è¡ï¼‰
        trend_weight = 1.0 - (consecutive_days / Config.TREND_CONSECUTIVE_DAYS) * 0.3
    
    direction = "bear" if current_above_ma else "bull"  # æ”¶ç›Šç‡<MA = å€ºåˆ¸ç‰›å¸‚
    
    return {
        "regime": regime,
        "consecutive_days": consecutive_days,
        "trend_weight": trend_weight,
        "direction": direction
    }


def calculate_composite_score(row, percentile, shibor_change=None, erp=None, spread_change=None, 
                              market_regime=None, shibor_change_std=None, spread_change_std=None):
    """
    è®¡ç®—ä¹°å…¥ä»·å€¼è¯„åˆ†ï¼ˆ0-100ï¼‰
    
    æ ¸å¿ƒé€»è¾‘ï¼šé«˜åˆ† = å€¼å¾—ä¹°å…¥ï¼ˆå€ºåˆ¸ä¾¿å®œï¼‰
    
    ä¸»è¦å› å­ï¼ˆä¼°å€¼ä¸ºç‹ï¼‰ï¼š
    - æ”¶ç›Šç‡åˆ†ä½æ•°è¶Šé«˜ = å€ºåˆ¸è¶Šä¾¿å®œ = è¶Šå€¼å¾—ä¹°
    
    è¾…åŠ©å› å­ï¼ˆå…¨éƒ¨ä½¿ç”¨è¿ç»­è¯„åˆ†ï¼Œé¿å…çªå˜ï¼‰ï¼š
    - è¶‹åŠ¿å› å­ï¼šåŸºäºæ”¶ç›Šç‡åç¦»MA60çš„ç¨‹åº¦ï¼Œè¿ç»­æ˜ å°„
    - RSIå› å­ï¼šåŸºäºRSIåç¦»ä¸­æ€§å€¼çš„ç¨‹åº¦ï¼Œè¿ç»­æ˜ å°„
    - èµ„é‡‘é¢ï¼šShiborå˜åŒ–çº¿æ€§æ˜ å°„
    - ä¸­ç¾åˆ©å·®ï¼šåˆ©å·®å˜åŒ–çº¿æ€§æ˜ å°„
    - å®è§‚å¯¹å†²ï¼šERPçº¿æ€§æ˜ å°„
    """
    score = Config.SCORE_BASE
    
    # è·å–å¸‚åœºçŠ¶æ€æƒé‡
    trend_weight = 1.0
    if market_regime is not None:
        trend_weight = market_regime.get("trend_weight", 1.0)
    
    # ã€æ ¸å¿ƒã€‘ä¼°å€¼ï¼šæ”¶ç›Šç‡åˆ†ä½æ•°è¶Šé«˜ = å€ºåˆ¸è¶Šä¾¿å®œ = è¶Šå€¼å¾—ä¹°
    score += (percentile - 50) * Config.SCORE_PERCENTILE_WEIGHT

    # ã€åŠ¨æ€ã€‘è¶‹åŠ¿å› å­ï¼šè¿ç»­è¯„åˆ†ï¼ŒåŸºäºåç¦»MA60çš„ç¨‹åº¦
    # åç¦»è¶Šå¤§ï¼Œåˆ†æ•°å½±å“è¶Šå¤§ï¼›åœ¨å‡çº¿é™„è¿‘æ—¶å½±å“å¾ˆå°
    # deviation > 0 è¡¨ç¤ºæ”¶ç›Šç‡é«˜äºMA60ï¼ˆç†Šå¸‚ï¼‰ï¼Œåº”è¯¥åŠ åˆ†
    # deviation < 0 è¡¨ç¤ºæ”¶ç›Šç‡ä½äºMA60ï¼ˆç‰›å¸‚ï¼‰ï¼Œåº”è¯¥å‡åˆ†
    # ã€ä¿®å¤ã€‘åœ¨å•è¾¹ç†Šå¸‚æ—¶é™ä½è¶‹åŠ¿å› å­æƒé‡ï¼Œé¿å…ä¸ä¼°å€¼é‡å¤è®¡åˆ†
    if 'MA60' in row.index and pd.notna(row['MA60']) and row['MA60'] > 0:
        # è®¡ç®—åç¦»ç¨‹åº¦ï¼š(yield - MA60) / MA60 * 100ï¼Œå¾—åˆ°ç™¾åˆ†æ¯”åç¦»
        deviation_pct = (row['yield'] - row['MA60']) / row['MA60'] * 100
        # å½’ä¸€åŒ–ï¼šå‡è®¾åç¦»è¶…è¿‡5%ä¸ºæç«¯æƒ…å†µ
        normalized = deviation_pct / 5.0
        normalized = max(-1, min(1, normalized))
        
        # åœ¨æŒç»­åç¦»ç†Šå¸‚ï¼ˆåˆ©ç‡ä¸Šè¡Œè¶‹åŠ¿ï¼‰æ—¶ï¼Œè¶‹åŠ¿å› å­ä¸ä¼°å€¼å› å­æ–¹å‘ä¸€è‡´
        # ä¸ºé¿å…é‡å¤è®¡åˆ†ï¼Œé¢å¤–é™ä½æƒé‡
        extra_weight = 1.0
        if market_regime is not None:
            if market_regime.get("regime") == "extended" and market_regime.get("direction") == "bear":
                extra_weight = 0.3  # æŒç»­åç¦»ç†Šå¸‚æ—¶è¶‹åŠ¿å› å­æƒé‡é™è‡³30%
        
        trend_bonus = normalized * Config.SCORE_TREND_BONUS * trend_weight * extra_weight
        score += trend_bonus

    # ã€åŠ¨æ€ã€‘RSIå› å­ï¼šè¿ç»­è¯„åˆ†ï¼ŒåŸºäºåç¦»ä¸­æ€§å€¼(50)çš„ç¨‹åº¦
    # RSI > 50 è¡¨ç¤ºæ”¶ç›Šç‡å¯èƒ½ä¸‹è·Œï¼ˆå€ºåˆ¸ä¸Šæ¶¨ï¼‰ï¼Œåº”è¯¥åŠ åˆ†
    # RSI < 50 è¡¨ç¤ºæ”¶ç›Šç‡å¯èƒ½ä¸Šæ¶¨ï¼ˆå€ºåˆ¸ä¸‹è·Œï¼‰ï¼Œåº”è¯¥å‡åˆ†
    # ã€ä¼˜åŒ–3ã€‘åœ¨æŒç»­åç¦»ç‰›å¸‚æ—¶å‰Šå¼±RSIï¼Œé¿å…"è¶Šæ¶¨è¶ŠåŠ åˆ†"å¯¼è‡´æ¥é£åˆ€
    if 'RSI' in row.index and pd.notna(row['RSI']):
        # è®¡ç®—åç¦»ä¸­æ€§å€¼çš„ç¨‹åº¦
        rsi_deviation = (row['RSI'] - 50) / 50  # å½’ä¸€åŒ–åˆ° [-1, 1]
        rsi_bonus = rsi_deviation * Config.SCORE_RSI_BONUS * trend_weight
        
        # åœ¨æŒç»­åç¦»ç‰›å¸‚ï¼ˆåˆ©ç‡ä¸‹è¡Œè¶‹åŠ¿ï¼‰æ—¶ï¼ŒRSIå¯èƒ½æŒç»­é«˜ä½
        # æ­¤æ—¶RSIä¿¡å·ä¸å¯é ï¼Œå‰Šå¼±å…¶æƒé‡
        if market_regime is not None:
            if market_regime.get("regime") == "extended" and market_regime.get("direction") == "bull":
                rsi_bonus *= 0.5  # æŒç»­åç¦»ç‰›å¸‚æ—¶RSIæƒé‡é™è‡³50%
        
        score += rsi_bonus

    # ã€è¾…åŠ©ã€‘æµåŠ¨æ€§å˜åŒ–ï¼šä½¿ç”¨å†å²æ³¢åŠ¨ç‡å½’ä¸€åŒ–
    # ã€ä¼˜åŒ–ã€‘åŒæ ·çš„bpå˜åŒ–åœ¨ä¸åŒå¹´ä»½æ„ä¹‰ä¸åŒï¼Œç”¨z-scoreå½’ä¸€åŒ–
    if shibor_change is not None and not np.isnan(shibor_change):
        if shibor_change_std is not None and not np.isnan(shibor_change_std) and shibor_change_std > 0:
            # ä½¿ç”¨å†å²æ³¢åŠ¨ç‡å½’ä¸€åŒ–ï¼ˆz-score / 2ï¼Œä½¿Â±2stdæ˜ å°„åˆ°Â±1ï¼‰
            z_score = shibor_change / shibor_change_std
            normalized = np.clip(z_score / 2, -1, 1)
        else:
            # å›é€€åˆ°å›ºå®šé˜ˆå€¼
            normalized = -shibor_change / Config.SHIBOR_MAX_CHANGE
            normalized = max(-1, min(1, normalized))
        # Shiborä¸Šå‡ï¼ˆèµ„é‡‘æ”¶ç´§ï¼‰åˆ©ç©ºå€ºå¸‚ï¼Œå–è´Ÿå·
        score += -normalized * Config.SCORE_LIQUIDITY_PENALTY

    # ã€è¾…åŠ©ã€‘å®è§‚å¯¹å†²ï¼šERP ä½œä¸ºæç«¯é£é™©è¿‡æ»¤å™¨
    # ã€ä¿®å¤ã€‘æ”¹ä¸ºé˜¶æ¢¯å¼è¯„åˆ†ï¼Œè€Œéçº¿æ€§è¿ç»­è¯„åˆ†
    # ERP æä½ï¼ˆ<1.5ï¼‰ï¼šè‚¡å¸‚æ³¡æ²«ï¼Œå€ºåˆ¸æœ‰å¸å¼•åŠ›ï¼Œä¸æ‰£åˆ†
    # ERP æé«˜ï¼ˆ>6ï¼‰ï¼šè‚¡å¸‚æå…·æ€§ä»·æ¯”ï¼Œå€ºåˆ¸å¸å¼•åŠ›ä¸‹é™ï¼Œé€‚åº¦æ‰£åˆ†
    # ERP ä¸­æ€§ï¼ˆ1.5-6ï¼‰ï¼šä¸å½±å“è¯„åˆ†
    if erp is not None and not np.isnan(erp):
        if erp < 1.5:
            # è‚¡å¸‚æ³¡æ²«ï¼Œå€ºåˆ¸ç›¸å¯¹æœ‰å¸å¼•åŠ›ï¼Œå¯ä»¥å°å¹…åŠ åˆ†
            score += 5
        elif erp > 6:
            # è‚¡å¸‚æå…·æ€§ä»·æ¯”ï¼Œå€ºåˆ¸å¸å¼•åŠ›ä¸‹é™
            score -= 10
        # ä¸­é—´åŒºåŸŸä¸å½±å“è¯„åˆ†

    # ã€è¾…åŠ©ã€‘ä¸­ç¾åˆ©å·®å˜åŒ–ï¼šä½¿ç”¨å†å²æ³¢åŠ¨ç‡å½’ä¸€åŒ–
    # ã€ä¼˜åŒ–ã€‘åŒæ ·çš„bpå˜åŒ–åœ¨ä¸åŒå¹´ä»½æ„ä¹‰ä¸åŒï¼Œç”¨z-scoreå½’ä¸€åŒ–
    if spread_change is not None and not np.isnan(spread_change):
        if spread_change_std is not None and not np.isnan(spread_change_std) and spread_change_std > 0:
            # ä½¿ç”¨å†å²æ³¢åŠ¨ç‡å½’ä¸€åŒ–ï¼ˆz-score / 2ï¼Œä½¿Â±2stdæ˜ å°„åˆ°Â±1ï¼‰
            z_score = spread_change / spread_change_std
            normalized = np.clip(z_score / 2, -1, 1)
        else:
            # å›é€€åˆ°å›ºå®šé˜ˆå€¼
            normalized = spread_change / Config.SPREAD_MAX_CHANGE
            normalized = max(-1, min(1, normalized))
        # åˆ©å·®æ”¶çª„ï¼ˆå˜å¥½ï¼‰åˆ©å¥½å€ºå¸‚
        score += normalized * Config.SCORE_LIQUIDITY_PENALTY

    return max(0, min(100, score))


def compute_backtest(df: pd.DataFrame, horizon_days: int = 126) -> dict:
    """åŸºäºå†å²è¯„åˆ†åšä¸€ä¸ªç®€å•å›æµ‹

    horizon_days: å‰ç»å¤©æ•°ï¼ˆäº¤æ˜“æ—¥ï¼‰ï¼Œé»˜è®¤çº¦ 6 ä¸ªæœˆ
    è¿”å›æŒ‰è¯„åˆ†åˆ†æ¡¶åçš„å¹³å‡æœªæ¥æ”¶ç›Šï¼ˆ%ï¼‰å’Œå•è°ƒæ€§æ£€éªŒç»“æœ
    
    ã€ä¼˜åŒ–1ã€‘å›æµ‹ç›®æ ‡ä»"åˆ©ç‡å˜åŠ¨"å‡çº§ä¸º"ä»·æ ¼/æ”¶ç›Š"
    ä½¿ç”¨ä¹…æœŸè¿‘ä¼¼è®¡ç®—çœŸå®æ”¶ç›Šï¼Œè€Œéä»…çœ‹åˆ©ç‡å˜åŠ¨æ–¹å‘
    """
    bt_df = df.copy()

    # ã€ä¿®å¤ä¿¡æ¯æ³„æ¼ã€‘ä½¿ç”¨ expanding percentileï¼Œåªç”¨"å½“æ—¶ä¹‹å‰"çš„æ•°æ®
    # æœ€å°‘éœ€è¦252å¤©ï¼ˆçº¦1å¹´ï¼‰æ•°æ®æ‰å¼€å§‹è®¡ç®—åˆ†ä½æ•°
    bt_df["bt_percentile"] = (
        bt_df["yield"]
        .expanding(min_periods=252)
        .apply(lambda x: stats.percentileofscore(x, x.iloc[-1]), raw=False)
    )

    # è®¡ç®—ERPç”¨äºè¯„åˆ†
    def _calc_erp(row: pd.Series) -> float | None:
        pe_val = row.get("pe")
        if pd.isna(pe_val) or pe_val <= 0:
            return None
        stock_yield = 100 / float(pe_val)
        return stock_yield - float(row["yield"])

    bt_df["bt_erp"] = bt_df.apply(_calc_erp, axis=1)

    # è®¡ç®—æ¯æ—¥ç»¼åˆè¯„åˆ†ï¼ˆå¿½ç•¥æŠ€æœ¯æŒ‡æ ‡å°šæœªå°±ç»ªçš„æ—©æœŸæ ·æœ¬ï¼‰
    def _safe_score(idx: int, row: pd.Series) -> float | None:
        required_cols = ["yield", "MA60", "MACD", "Signal_Line", "RSI", "bt_percentile"]
        if any(pd.isna(row[c]) for c in required_cols):
            return None
        # è®¡ç®—å½“å‰ä½ç½®çš„å¸‚åœºçŠ¶æ€
        market_regime = detect_market_regime(bt_df, idx)
        return float(
            calculate_composite_score(
                row,
                float(row["bt_percentile"]),
                shibor_change=row.get("shibor_change"),
                erp=row.get("bt_erp"),
                spread_change=row.get("spread_change"),
                market_regime=market_regime,
                shibor_change_std=row.get("shibor_change_std"),
                spread_change_std=row.get("spread_change_std"),
            )
        )

    bt_df["bt_score"] = [_safe_score(i, row) for i, row in bt_df.iterrows()]

    # ã€ä¼˜åŒ–1ã€‘è®¡ç®—çœŸå®æ”¶ç›Šè€Œéä»…åˆ©ç‡å˜åŠ¨
    # ä½¿ç”¨ä¹…æœŸè¿‘ä¼¼ï¼šæ”¶ç›Š â‰ˆ ä¹…æœŸ Ã— (åˆ©ç‡å˜åŠ¨)
    # ä¹…æœŸéšåˆ©ç‡æ°´å¹³å˜åŒ–ï¼šé«˜åˆ©ç‡æ—¶ä¹…æœŸæ›´é•¿ï¼ˆçº¦8å¹´ï¼‰ï¼Œä½åˆ©ç‡æ—¶ä¹…æœŸè¾ƒçŸ­ï¼ˆçº¦6å¹´ï¼‰
    bt_df["yield_future"] = bt_df["yield"].shift(-horizon_days)
    bt_df["yield_change"] = bt_df["yield"] - bt_df["yield_future"]  # æ­£å€¼=åˆ©ç‡ä¸‹é™=å€ºåˆ¸æ¶¨
    
    # åŠ¨æ€ä¹…æœŸï¼šåˆ©ç‡>3%æ—¶ä¹…æœŸçº¦8å¹´ï¼Œåˆ©ç‡<2%æ—¶ä¹…æœŸçº¦6å¹´ï¼Œçº¿æ€§æ’å€¼
    bt_df["duration"] = np.clip(6 + (bt_df["yield"] - 2) * 2, 5, 10)
    
    # è¿‘ä¼¼æ”¶ç›Šï¼ˆ%ï¼‰= ä¹…æœŸ Ã— åˆ©ç‡å˜åŠ¨ï¼ˆ%ï¼‰+ ç¥¨æ¯æ”¶ç›Šï¼ˆæŒ‰å¹´åŒ–2%ä¼°ç®—ï¼Œhorizon_days/252å¹´ï¼‰
    # åˆ©ç‡å˜åŠ¨å·²ç»æ˜¯ç™¾åˆ†ç‚¹ï¼Œç›´æ¥ä¹˜ä»¥ä¹…æœŸå¾—åˆ°è¿‘ä¼¼ä»·æ ¼å˜åŠ¨ç™¾åˆ†æ¯”
    coupon_return = 2.0 * (horizon_days / 252)  # å¹´åŒ–ç¥¨æ¯çº¦2%
    bt_df["forward_return"] = bt_df["duration"] * bt_df["yield_change"] + coupon_return
    
    # åŒæ—¶ä¿ç•™åŸå§‹bpå˜åŠ¨ç”¨äºå‚è€ƒ
    bt_df["forward_yield_change_bp"] = bt_df["yield_change"] * 100.0

    valid = bt_df.dropna(subset=["bt_score", "forward_return"]).copy()

    buckets_def = [(0, 20), (20, 40), (40, 60), (60, 80), (80, 101)]
    buckets: list[dict] = []
    for low, high in buckets_def:
        mask = (valid["bt_score"] >= low) & (valid["bt_score"] < high)
        sub = valid[mask]
        if sub.empty:
            avg_return = None
            avg_yield_change_bp = None
            count = 0
        else:
            avg_return = float(sub["forward_return"].mean())
            avg_yield_change_bp = float(sub["forward_yield_change_bp"].mean())
            count = int(sub.shape[0])
        buckets.append(
            {
                "min_score": low,
                "max_score": 100 if high == 101 else high,
                "count": count,
                "avg_forward_return": avg_return,  # æ–°å¢ï¼šçœŸå®æ”¶ç›Šï¼ˆ%ï¼‰
                "avg_forward_yield_change_bp": avg_yield_change_bp,  # ä¿ç•™ï¼šåˆ©ç‡å˜åŠ¨ï¼ˆbpï¼‰
            }
        )

    # ã€ä¼˜åŒ–2ã€‘å•è°ƒæ€§ä½“æ£€ï¼šæ£€æŸ¥åˆ†æ•°æ˜¯å¦çœŸçš„æœ‰ç”¨
    # é«˜åˆ†æ¡¶çš„æ”¶ç›Šåº”è¯¥ >= ä½åˆ†æ¡¶çš„æ”¶ç›Š
    valid_returns = [b["avg_forward_return"] for b in buckets if b["avg_forward_return"] is not None]
    is_monotonic = True
    if len(valid_returns) >= 2:
        is_monotonic = all(
            valid_returns[i] <= valid_returns[i + 1]
            for i in range(len(valid_returns) - 1)
        )
    
    # è®¡ç®—å•è°ƒæ€§å¾—åˆ†ï¼šæœ‰å¤šå°‘å¯¹ç›¸é‚»æ¡¶æ»¡è¶³å•è°ƒå…³ç³»
    monotonic_pairs = 0
    total_pairs = 0
    for i in range(len(valid_returns) - 1):
        total_pairs += 1
        if valid_returns[i] <= valid_returns[i + 1]:
            monotonic_pairs += 1
    monotonic_score = monotonic_pairs / total_pairs if total_pairs > 0 else 1.0

    # ç”Ÿæˆè¯„åˆ†æ—¶é—´åºåˆ—ï¼ˆç”¨äºæŠ˜çº¿å›¾ï¼‰
    score_series = bt_df[["date", "yield", "bt_score"]].dropna(subset=["bt_score"]).copy()
    score_series["date"] = score_series["date"].dt.strftime("%Y-%m-%d")
    score_series = score_series.rename(columns={"bt_score": "score"})
    # æ¯10å¤©å–ä¸€ä¸ªç‚¹ï¼Œå‡å°‘æ•°æ®é‡
    score_series_sampled = score_series.iloc[::10].to_dict(orient="records")

    return {
        "horizon_days": horizon_days,
        "buckets": buckets,
        "is_monotonic": is_monotonic,
        "monotonic_score": monotonic_score,
        "monotonic_msg": "âœ… å•è°ƒæˆç«‹ï¼Œåˆ†æ•°å¯ä¿¡" if is_monotonic else f"âš ï¸ å•è°ƒæ€§ç ´å ({monotonic_pairs}/{total_pairs})ï¼Œå»ºè®®å®¡è§†å› å­",
        "score_history": score_series_sampled  # æ–°å¢ï¼šè¯„åˆ†å†å²æ—¶é—´åºåˆ—
    }

# ==========================================
# ğŸ“¥ æ•°æ®è·å–
# ==========================================

def get_final_data():
    print("ğŸš€ æ­£åœ¨å¯åŠ¨è‡ªåŠ¨ç ”æŠ¥ç‰ˆ...")
    start_date = (datetime.datetime.now() - datetime.timedelta(days=Config.DATA_YEARS*365)).strftime("%Y%m%d")
    
    # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ä¸´æ—¶ç¦ç”¨ SSL éªŒè¯ï¼ˆä»…åœ¨ akshare è°ƒç”¨æœŸé—´ï¼‰
    with disable_ssl_verification():
        # 1. å›½å€ºï¼ˆä¸­ç¾ï¼‰
        print("ğŸ“¡ 1/4 è·å–ä¸­ç¾å›½å€ºæ•°æ®...")
        try:
            df_bond_raw = ak.bond_zh_us_rate(start_date=start_date)
            # ä¸­å›½10å¹´æœŸå›½å€º
            df_bond = df_bond_raw[['æ—¥æœŸ', 'ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´']].dropna()
            df_bond.columns = ['date', 'yield']
            df_bond['date'] = pd.to_datetime(df_bond['date'])
            df_bond['yield'] = pd.to_numeric(df_bond['yield'])
            df_bond.sort_values(by='date', inplace=True)
            
            # ç¾å›½10å¹´æœŸå›½å€º
            df_us_bond = df_bond_raw[['æ—¥æœŸ', 'ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´']].dropna()
            df_us_bond.columns = ['date', 'us_yield']
            df_us_bond['date'] = pd.to_datetime(df_us_bond['date'])
            df_us_bond['us_yield'] = pd.to_numeric(df_us_bond['us_yield'])
            print(f"   âœ… ä¸­ç¾å›½å€ºæ•°æ®è·å–æˆåŠŸ")
        except Exception as e:
            print(f"âŒ é”™è¯¯: å›½å€ºæ•°æ®å¤±è´¥ {e}")
            return None

        # 2. è‚¡å¸‚
        print("ğŸ“¡ 2/4 è·å–è‚¡å¸‚ä¼°å€¼...")
        try:
            df_stock = ak.stock_zh_index_value_csindex(symbol="000300")
            pe_col = 'å¸‚ç›ˆç‡1' if 'å¸‚ç›ˆç‡1' in df_stock.columns else 'å¸‚ç›ˆç‡2'
            df_stock = df_stock[['æ—¥æœŸ', pe_col]].dropna()
            df_stock.columns = ['date', 'pe']
            df_stock['date'] = pd.to_datetime(df_stock['date'])
            df_stock['pe'] = pd.to_numeric(df_stock['pe'])
            print(f"   âœ… è‚¡å¸‚æ•°æ®è·å–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: è‚¡å¸‚æ•°æ®è·å–å¤±è´¥ï¼Œå¿½ç•¥è‚¡å€ºè”åŠ¨ã€‚")
            df_stock = pd.DataFrame(columns=['date', 'pe'])

        # 3. æµåŠ¨æ€§
        print("ğŸ“¡ 3/4 è·å–æµåŠ¨æ€§æ•°æ®...")
        try:
            df_shibor = ak.macro_china_shibor_all()
            target_col = None
            possible_names = ['éš”å¤œ', 'ON', 'O/N', '1D', 'Day']
            for name in possible_names:
                if name in df_shibor.columns:
                    target_col = name
                    break
            if target_col is None and len(df_shibor.columns) >= 2:
                target_col = df_shibor.columns[1]
            
            if target_col is not None:
                df_shibor = df_shibor[['æ—¥æœŸ', target_col]].dropna()
                df_shibor.columns = ['date', 'shibor']
                df_shibor['date'] = pd.to_datetime(df_shibor['date'])
                df_shibor['shibor'] = pd.to_numeric(df_shibor['shibor'])
                print(f"   âœ… æµåŠ¨æ€§æ•°æ®è·å–æˆåŠŸ")
            else:
                raise ValueError("æœªæ‰¾åˆ°åˆ©ç‡åˆ—")

        except Exception as e:
            print(f"âš ï¸ è­¦å‘Š: æµåŠ¨æ€§æ•°æ®è·å–å¤±è´¥ ({e})")
            df_shibor = pd.DataFrame(columns=['date', 'shibor'])

    # 4. åˆå¹¶æ•°æ®ï¼ˆä¸éœ€è¦ç½‘ç»œè¯·æ±‚ï¼Œåœ¨ with å—å¤–æ‰§è¡Œï¼‰
    print("ğŸ“¡ 4/4 åˆå¹¶æ•°æ®...")
    df = pd.merge(df_bond, df_stock, on='date', how='left')
    df = pd.merge(df, df_shibor, on='date', how='left')
    df = pd.merge(df, df_us_bond, on='date', how='left')  # æ·»åŠ ç¾å›½å›½å€º
    df.ffill(inplace=True)
    
    # è®¡ç®—ä¸­ç¾åˆ©å·®
    df['cn_us_spread'] = df['yield'] - df['us_yield']
    # è®¡ç®—åˆ©å·®å˜åŒ–ï¼ˆæ­£å€¼=æ”¶çª„/å˜å¥½ï¼Œè´Ÿå€¼=èµ°é˜”/å˜å·®ï¼‰
    # æ³¨æ„ï¼šåˆ©å·®å˜åŒ– = å½“å‰åˆ©å·® - Nå¤©å‰åˆ©å·®
    # å¦‚æœåˆ©å·®ä»-2.5%å˜æˆ-2.0%ï¼Œå˜åŒ–=+0.5%ï¼Œè¯´æ˜æ”¶çª„ï¼ˆå˜å¥½ï¼‰
    df['spread_change'] = df['cn_us_spread'] - df['cn_us_spread'].shift(Config.SPREAD_LOOKBACK)
    # ã€ä¼˜åŒ–ã€‘è®¡ç®—åˆ©å·®å˜åŒ–çš„å†å²æ³¢åŠ¨ç‡ï¼Œç”¨äºå½’ä¸€åŒ–
    df['spread_change_std'] = df['spread_change'].rolling(252).std()
    
    # è®¡ç®—Shiborå˜åŒ–ï¼ˆæ­£å€¼=æ”¶ç´§ï¼Œè´Ÿå€¼=å®½æ¾ï¼‰
    df['shibor_change'] = df['shibor'] - df['shibor'].shift(Config.SHIBOR_LOOKBACK)
    # ã€ä¼˜åŒ–ã€‘è®¡ç®—Shiborå˜åŒ–çš„å†å²æ³¢åŠ¨ç‡ï¼Œç”¨äºå½’ä¸€åŒ–
    df['shibor_change_std'] = df['shibor_change'].rolling(252).std()
    print(f"   âœ… æ•°æ®åˆå¹¶å®Œæˆï¼Œå…± {len(df)} æ¡è®°å½•")
    
    return df, df_bond, df_stock, df_shibor, df_us_bond

# ==========================================
# ğŸ“Š ä¸»ç¨‹åºé€»è¾‘
# ==========================================

def run_system():
    result = get_final_data()
    if result is None: return
    df, df_bond, df_stock, df_shibor, df_us_bond = result

    df = calculate_technical_indicators(df)
    # å…ˆè®¡ç®—ä¸€éå…¨å†å²å›æµ‹ç»“æœ
    backtest = compute_backtest(df)
    last = df.iloc[-1]
    
    recent_df = df[df['date'] > (df.iloc[-1]['date'] - datetime.timedelta(days=Config.DATA_YEARS*365))]
    percentile = stats.percentileofscore(recent_df['yield'], last['yield'])
    
    # çŠ¶æ€åˆ¤å®š
    val_status = "ğŸ”´ æè´µ" if percentile < Config.PERCENTILE_EXPENSIVE else ("ğŸŸ¢ ä¾¿å®œ" if percentile > Config.PERCENTILE_CHEAP else "âš–ï¸ é€‚ä¸­")
    
    # è®¡ç®—ERPå’Œå®è§‚çŠ¶æ€
    macro_msg = "âšªï¸ ç¼ºå¤±"
    pe_val_str = "N/A"
    erp = None
    pe_val = last.get('pe')
    if pd.notna(pe_val) and pe_val > 0:
        pe_val_str = f"PE={pe_val:.1f}"
        stock_yield = 100 / pe_val
        erp = stock_yield - last['yield']
        # çŠ¶æ€æ–‡å­—ä»ç„¶ä¿ç•™ï¼Œç”¨äºå±•ç¤ºï¼ˆä½†è¯„åˆ†ç”¨è¿ç»­å€¼ï¼‰
        if erp > 5.5: macro_msg = f"âš ï¸ è‚¡å¸‚æå…·æ€§ä»·æ¯” (ERP={erp:.1f})"
        elif erp < 2.0: macro_msg = f"âœ… è‚¡å¸‚æ³¡æ²« (ERP={erp:.1f})"
        else: macro_msg = f"âš–ï¸ è‚¡å€ºå¹³è¡¡ (ERP={erp:.1f})"
        
    # æµåŠ¨æ€§å˜åŒ–åˆ¤å®š
    liquidity_msg = "âšªï¸ ç¼ºå¤±"
    shibor_val_str = "N/A"
    shibor_change_str = "N/A"
    shibor_val = last.get('shibor')
    shibor_change = last.get('shibor_change')
    if pd.notna(shibor_val) and shibor_val > 0:
        shibor_val_str = f"{shibor_val:.2f}%"
        if pd.notna(shibor_change):
            shibor_change_str = f"{shibor_change:+.2f}%"
            # çŠ¶æ€æ–‡å­—ç”¨äºå±•ç¤ºï¼Œè¯„åˆ†ç”¨è¿ç»­å€¼
            if shibor_change > 0.3:
                liquidity_msg = f"ğŸ”¥ èµ„é‡‘æ”¶ç´§ ({shibor_change:+.0f}bp)"
            elif shibor_change < -0.3:
                liquidity_msg = f"ğŸ’§ èµ„é‡‘å®½æ¾ ({shibor_change:+.0f}bp)"
            else:
                liquidity_msg = f"âš–ï¸ èµ„é‡‘å¹³ç¨³ ({shibor_change:+.0f}bp)"

    # ä¸­ç¾åˆ©å·®å˜åŒ–åˆ¤å®š
    spread_msg = "âšªï¸ ç¼ºå¤±"
    spread_val_str = "N/A"
    spread_change_str = "N/A"
    us_yield_str = "N/A"
    cn_us_spread = last.get('cn_us_spread')
    spread_change = last.get('spread_change')
    us_yield = last.get('us_yield')
    if pd.notna(cn_us_spread) and pd.notna(us_yield):
        spread_val_str = f"{cn_us_spread:.2f}%"
        us_yield_str = f"{us_yield:.2f}%"
        if pd.notna(spread_change):
            spread_change_str = f"{spread_change:+.2f}%"
            # çŠ¶æ€æ–‡å­—ç”¨äºå±•ç¤ºï¼Œè¯„åˆ†ç”¨è¿ç»­å€¼
            if spread_change > 0.3:
                spread_msg = f"âœ… åˆ©å·®æ”¶çª„ ({spread_change:+.0f}bp)"
            elif spread_change < -0.3:
                spread_msg = f"âš ï¸ åˆ©å·®èµ°é˜” ({spread_change:+.0f}bp)"
            else:
                spread_msg = f"âš–ï¸ åˆ©å·®å¹³ç¨³ ({spread_change:+.0f}bp)"

    # æ£€æµ‹å¸‚åœºçŠ¶æ€
    market_regime = detect_market_regime(df)
    regime_str = "æŒç»­åç¦»" if market_regime["regime"] == "extended" else "å‡å€¼å›å½’"
    direction_str = "ç‰›å¸‚" if market_regime["direction"] == "bull" else "ç†Šå¸‚"
    regime_msg = f"{regime_str}({direction_str}, è¿ç»­{market_regime['consecutive_days']}å¤©)"
    
    # ä½¿ç”¨è¿ç»­å€¼è®¡ç®—è¯„åˆ†
    shibor_change_std = last.get('shibor_change_std')
    spread_change_std = last.get('spread_change_std')
    score = calculate_composite_score(
        last, 
        percentile, 
        shibor_change=shibor_change if pd.notna(shibor_change) else None,
        erp=erp,
        spread_change=spread_change if pd.notna(spread_change) else None,
        market_regime=market_regime,
        shibor_change_std=shibor_change_std if pd.notna(shibor_change_std) else None,
        spread_change_std=spread_change_std if pd.notna(spread_change_std) else None
    )
    
    # å»ºè®®ï¼šé«˜åˆ† = å€¼å¾—ä¹°å…¥ï¼Œä½åˆ† = ä¸å€¼å¾—ä¹°
    suggestion_con = "" 
    suggestion_agg = "" 
    weather = ""
    if score >= Config.WEATHER_SUNNY:
        weather = "â˜€ï¸ çƒˆæ—¥ (æå¥½)"
        suggestion_con = "ã€å€¼å¾—ä¹°å…¥ã€‘å€ºåˆ¸ä¾¿å®œï¼Œå½“å‰æ˜¯è¾ƒå¥½çš„ä¹°ç‚¹ï¼Œå¯ä»¥å¤§èƒ†å»ºä»“ã€‚"
        suggestion_agg = "ã€é‡ä»“å‡ºå‡»ã€‘ä¼°å€¼æä½ï¼Œå¯è€ƒè™‘é•¿ä¹…æœŸå€ºåŸºæˆ–æ æ†å€ºåŸºã€‚"
    elif score >= Config.WEATHER_CLEAR:
        weather = "ğŸŒ¤ï¸ æ™´æœ— (è¾ƒå¥½)"
        suggestion_con = "ã€å¯ä»¥ä¹°å…¥ã€‘ä¼°å€¼åˆç†åä½ï¼Œé€‚åˆå®šæŠ•æˆ–åˆ†æ‰¹å»ºä»“ã€‚"
        suggestion_agg = "ã€é€¢ä½åŠ ä»“ã€‘å¦‚é‡å›è°ƒï¼Œå¯å¤§èƒ†åŠ ä»“ã€‚"
    elif score >= Config.WEATHER_CLOUDY:
        weather = "â˜ï¸ å¤šäº‘ (éœ‡è¡)"
        suggestion_con = "ã€æŒæœ‰è§‚æœ›ã€‘ä¼°å€¼ä¸­æ€§ï¼Œå·²æŒä»“å¯ç»§ç»­æŒæœ‰ï¼Œæ–°èµ„é‡‘æš‚ç¼“ã€‚"
        suggestion_agg = "ã€å°ä»“è¯•æ¢ã€‘å¯å°ä»“ä½å‚ä¸ï¼Œç­‰å¾…æ›´å¥½æœºä¼šã€‚"
    elif score >= Config.WEATHER_RAINY:
        weather = "ğŸŒ§ï¸ å°é›¨ (è¾ƒå·®)"
        suggestion_con = "ã€æš‚ä¸å»ºè®®ä¹°å…¥ã€‘ä¼°å€¼åè´µï¼Œå»ºè®®ç­‰å¾…æ›´å¥½çš„å…¥åœºæ—¶æœºã€‚"
        suggestion_agg = "ã€å‡ä»“è§‚æœ›ã€‘å·²æœ‰æŒä»“å¯é€æ­¥æ­¢ç›ˆï¼Œé”å®šåˆ©æ¶¦ã€‚"
    else:
        weather = "â›ˆï¸ æš´é›¨ (æå·®)"
        suggestion_con = "ã€ä¸å»ºè®®ä¹°å…¥ã€‘ä¼°å€¼è¿‡é«˜ï¼Œé£é™©å¤§äºæ”¶ç›Šï¼Œå»ºè®®å›é¿ã€‚"
        suggestion_agg = "ã€æ¸…ä»“å›é¿ã€‘æåº¦é«˜ä¼°ï¼Œè½¬å…¥è´§å¸åŸºé‡‘ç­‰å¾…æœºä¼šã€‚"

    # è·å–è„šæœ¬æ‰€åœ¨çš„ç»å¯¹æ ¹ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # æ•°æ®ç›®å½•
    data_dir = os.path.join(script_dir, "data")
    if not os.path.exists(data_dir):
        os.makedirs(data_dir)
        print(f"\nğŸ“‚ å·²åˆ›å»ºæ•°æ®æ–‡ä»¶å¤¹: data")

    # ç»ˆç«¯æ‰“å°
    print("\n" + "â–ˆ"*60)
    print(f"   ğŸ† å€ºåŸºæ™´é›¨è¡¨(Auto-Report)")
    print(f"   æ—¥æœŸ: {last['date'].strftime('%Y-%m-%d')} | 10å¹´å›½å€ºæ”¶ç›Šç‡: {last['yield']:.4f}%")
    print("â–ˆ"*60)
    print(f"\nğŸ”® ã€ç»¼åˆè¯„åˆ†ã€‘: {score:.1f} åˆ†  --->  {weather}")
    print(f"ğŸ“Š ã€å¸‚åœºçŠ¶æ€ã€‘: {regime_msg} (è¶‹åŠ¿å› å­æƒé‡: {market_regime['trend_weight']:.0%})")
    print("-" * 60)
    print(f"ğŸ’¡ æ“ä½œå»ºè®®:")
    print(f"   ğŸ¢ [ç¨³å¥å‹]: {suggestion_con}")
    print(f"   ğŸ‡ [æ¿€è¿›å‹]: {suggestion_agg}")
    print("â–ˆ"*60 + "\n")
    
    # å‡†å¤‡åŸå§‹æ•°æ®è®°å½•
    bond_records = df_bond[["date","yield"]].copy()
    bond_records["date"] = bond_records["date"].dt.strftime("%Y-%m-%d")
    stock_records = df_stock[["date","pe"]].copy() if set(["date","pe"]).issubset(df_stock.columns) else pd.DataFrame(columns=["date","pe"]) 
    if "date" in stock_records.columns:
        stock_records["date"] = pd.to_datetime(stock_records["date"]).dt.strftime("%Y-%m-%d")
    shibor_records = df_shibor[["date","shibor"]].copy() if set(["date","shibor"]).issubset(df_shibor.columns) else pd.DataFrame(columns=["date","shibor"]) 
    if "date" in shibor_records.columns:
        shibor_records["date"] = pd.to_datetime(shibor_records["date"]).dt.strftime("%Y-%m-%d")
    us_bond_records = df_us_bond[["date","us_yield"]].copy() if set(["date","us_yield"]).issubset(df_us_bond.columns) else pd.DataFrame(columns=["date","us_yield"])
    if "date" in us_bond_records.columns:
        us_bond_records["date"] = pd.to_datetime(us_bond_records["date"]).dt.strftime("%Y-%m-%d")
    
    # æ„å»ºå¯¼å‡ºæ•°æ®
    data_export = {
        "generated_at": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "conclusion": {
            "last_date": last['date'].strftime('%Y-%m-%d'),
            "last_yield": float(last['yield']),
            "score": float(score),
            "weather": weather,
            "percentile": float(percentile),
            "val_status": val_status,
            "trend_val": "ç‰›" if last['yield'] < last['MA60'] else "ç†Š",
            "trend_status": "ğŸŸ¢ Yield < MA60" if last['yield'] < last['MA60'] else "ğŸ”´ Yield > MA60",
            "macd_val": "å‘å¥½" if last['MACD'] < last['Signal_Line'] else "æ¶åŒ–",
            "macd_status": "ğŸŸ¢ æ­»å‰(è·Œ)" if last['MACD'] < last['Signal_Line'] else "ğŸ”´ é‡‘å‰(æ¶¨)",
            "rsi": float(last['RSI']) if pd.notna(last['RSI']) else None,
            "pe_val": pe_val_str,
            "macro_msg": macro_msg,
            "shibor_val": shibor_val_str,
            "shibor_change": shibor_change_str,
            "liquidity_msg": liquidity_msg,
            "spread_val": spread_val_str,
            "spread_change": spread_change_str,
            "spread_msg": spread_msg,
            "us_yield": us_yield_str,
            "market_regime": {
                "regime": market_regime["regime"],
                "regime_msg": regime_msg,
                "consecutive_days": market_regime["consecutive_days"],
                "trend_weight": market_regime["trend_weight"],
                "direction": market_regime["direction"]
            },
            "suggestion_con": suggestion_con,
            "suggestion_agg": suggestion_agg
        },
        "backtest": backtest,
        "raw": {
            "bond_10y": bond_records.to_dict(orient="records"),
            "stock_pe": stock_records.to_dict(orient="records"),
            "shibor_on": shibor_records.to_dict(orient="records"),
            "us_bond_10y": us_bond_records.to_dict(orient="records")
        }
    }
    
    # æ›´æ–°æ±‡æ€»æ–‡ä»¶ï¼ˆæŒ‰ last_date å»é‡ï¼ŒåŒä¸€å¤©åªä¿ç•™æœ€æ–°ä¸€æ¬¡è¿è¡Œï¼‰
    # åªæœ‰æœ€æ–°ä¸€æ¡ä¿ç•™åŸå§‹æ•°æ®ï¼ˆç”¨äºå›¾è¡¨ï¼‰ï¼Œå†å²è®°å½•åªä¿ç•™ç»“è®º
    all_ts_path = os.path.join(data_dir, "bondReports.ts")
    try:
        existing_reports = []
        if os.path.exists(all_ts_path):
            with open(all_ts_path, "r", encoding="utf-8") as f:
                content = f.read()
            begin = content.find("[")
            end = content.rfind("]")
            if begin != -1 and end != -1:
                array_str = content[begin:end+1]
                try:
                    existing_reports = json.loads(array_str)
                except json.JSONDecodeError:
                    print("âš ï¸ è§£æç°æœ‰æ•°æ®å¤±è´¥ï¼Œå°†é‡æ–°åˆ›å»º")
                    existing_reports = []
        
        # æŒ‰ last_date å»é‡ï¼šç§»é™¤ä¸æ–°æ•°æ®åŒä¸€å¤©çš„æ—§è®°å½•
        new_last_date = data_export["conclusion"]["last_date"]
        filtered_reports = [r for r in existing_reports if r.get("conclusion", {}).get("last_date") != new_last_date]
        
        # å†å²è®°å½•ç§»é™¤ raw æ•°æ®ï¼ˆå‡å°‘æ–‡ä»¶å¤§å°ï¼‰
        for report in filtered_reports:
            if "raw" in report:
                del report["raw"]
        
        # å°†æ–°æ•°æ®ï¼ˆåŒ…å« rawï¼‰æ’å…¥åˆ°æœ€å‰é¢
        filtered_reports.insert(0, data_export)
        
        # æŒ‰ generated_at é™åºæ’åº
        filtered_reports.sort(key=lambda x: x.get("generated_at", ""), reverse=True)
        
        # ç”Ÿæˆæ–°çš„æ±‡æ€»æ–‡ä»¶
        aggregated = "export const bondReports = " + json.dumps(filtered_reports, ensure_ascii=False, indent=2) + ";\nexport default bondReports;\n"
        with open(all_ts_path, "w", encoding="utf-8") as f:
            f.write(aggregated)
        print(f"âœ… æ±‡æ€»æ•°æ®å·²æ›´æ–°: {all_ts_path} (å…± {len(filtered_reports)} æ¡è®°å½•)")
    except Exception as e:
        print(f"âŒ æ±‡æ€»æ•°æ®æ›´æ–°å¤±è´¥: {e}")

if __name__ == "__main__":
    run_system()
