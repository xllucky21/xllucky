#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
LOFåŸºé‡‘å¥—åˆ©ç›‘æµ‹æ•°æ®è·å–è„šæœ¬
æ ¸å¿ƒæ”¹è¿›ï¼šä½¿ç”¨ã€ç›˜ä¸­å®æ—¶ä¼°å€¼ã€‘vsã€åœºå†…ä»·æ ¼ã€‘è®¡ç®—çœŸå®å¥—åˆ©æŠ˜æº¢ä»·
è€Œé T-1 å‡€å€¼ vs åœºå†…ä»·æ ¼ï¼ˆä¼šäº§ç”Ÿå‡ä¿¡å·ï¼‰
"""

import json
import os
import sys
import time
from datetime import datetime, date
import warnings
import ssl
import urllib3
import requests
import hashlib

# ==========================================
# ğŸ›¡ï¸ ç³»ç»Ÿåº•å±‚é…ç½®
# ==========================================
warnings.filterwarnings("ignore")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

try:
    ssl._create_default_https_context = ssl._create_unverified_context
except AttributeError:
    pass

old_session_request = requests.Session.request
def new_session_request(self, method, url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    })
    return old_session_request(self, method, url, *args, **kwargs)
requests.Session.request = new_session_request

old_get = requests.get
old_post = requests.post
def new_get(url, *args, **kwargs):
    kwargs['verify'] = False
    kwargs.setdefault('headers', {})['User-Agent'] = 'Mozilla/5.0'
    return old_get(url, *args, **kwargs)
def new_post(url, *args, **kwargs):
    kwargs['verify'] = False
    kwargs.setdefault('headers', {})['User-Agent'] = 'Mozilla/5.0'
    return old_post(url, *args, **kwargs)
requests.get = new_get
requests.post = new_post

import akshare as ak
import pandas as pd

# é…ç½®
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(SCRIPT_DIR, "data")
CACHE_DIR = os.path.join(SCRIPT_DIR, ".cache")  # ç¼“å­˜ç›®å½•
OUTPUT_FILENAME = "lof_data.ts"
OUTPUT_PATH = os.path.join(DATA_DIR, OUTPUT_FILENAME)

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# ==========================================
# ğŸ—„ï¸ ç¼“å­˜é…ç½®
# ==========================================
NAV_CACHE_FILE = os.path.join(CACHE_DIR, "nav_cache.json")  # T-1å‡€å€¼ç¼“å­˜
NAV_HISTORY_CACHE_FILE = os.path.join(CACHE_DIR, "nav_history_cache.json")  # å†å²å‡€å€¼ç¼“å­˜
PRICE_HISTORY_CACHE_FILE = os.path.join(CACHE_DIR, "price_history_cache.json")  # å†å²ä»·æ ¼ç¼“å­˜


def get_today_str():
    """è·å–ä»Šå¤©æ—¥æœŸå­—ç¬¦ä¸²"""
    return date.today().strftime('%Y-%m-%d')


def load_cache(cache_file):
    """åŠ è½½ç¼“å­˜æ–‡ä»¶"""
    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except:
            pass
    return {}


def save_cache(cache_file, data):
    """ä¿å­˜ç¼“å­˜æ–‡ä»¶"""
    with open(cache_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def get_codes_hash(codes):
    """è®¡ç®—åŸºé‡‘ä»£ç åˆ—è¡¨çš„hashï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ›´æ–°å†å²æ•°æ®"""
    return hashlib.md5(','.join(sorted(codes)).encode()).hexdigest()[:16]

# çƒ­é—¨LOFåŸºé‡‘åˆ—è¡¨
HOT_LOF_LIST = [
    ("501050", "åå¤ä¸Šè¯50AH", "ä¸Šè¯50AHä¼˜é€‰"),
    ("160119", "å—æ–¹ä¸­è¯500ETFè”æ¥", "ä¸­è¯500"),
    ("161017", "å¯Œå›½ä¸­è¯500", "ä¸­è¯500"),
    ("160706", "å˜‰å®æ²ªæ·±300", "æ²ªæ·±300"),
    ("160716", "å˜‰å®åŸºæœ¬é¢50", "åŸºæœ¬é¢50"),
    ("163407", "å…´å…¨æ²ªæ·±300", "æ²ªæ·±300"),
    ("501057", "åå¤åˆ›ä¸šæ¿åŠ¨é‡", "åˆ›ä¸šæ¿åŠ¨é‡"),
    ("161725", "æ‹›å•†ä¸­è¯ç™½é…’", "ä¸­è¯ç™½é…’"),
    ("161726", "æ‹›å•†ä¸­è¯ç…¤ç‚­", "ä¸­è¯ç…¤ç‚­"),
    ("161028", "å¯Œå›½ä¸­è¯æ–°èƒ½æºæ±½è½¦", "æ–°èƒ½æºè½¦"),
    ("160225", "å›½æ³°å›½è¯æœ‰è‰²é‡‘å±", "æœ‰è‰²é‡‘å±"),
    ("161024", "å¯Œå›½ä¸­è¯å†›å·¥", "ä¸­è¯å†›å·¥"),
    ("160628", "é¹åä¸­è¯å›½é˜²", "ä¸­è¯å›½é˜²"),
    ("160630", "é¹åä¸­è¯ä¼ åª’", "ä¸­è¯ä¼ åª’"),
    ("160633", "é¹åä¸­è¯ç¯ä¿", "ä¸­è¯ç¯ä¿"),
    ("160635", "é¹åä¸­è¯é“¶è¡Œ", "ä¸­è¯é“¶è¡Œ"),
    ("161720", "æ‹›å•†ä¸­è¯è¯åˆ¸", "ä¸­è¯è¯åˆ¸"),
    ("161116", "æ˜“æ–¹è¾¾ä¸­è¯é“¶è¡Œ", "ä¸­è¯é“¶è¡Œ"),
    ("161121", "æ˜“æ–¹è¾¾ä¸­è¯å†›å·¥", "ä¸­è¯å†›å·¥"),
    ("161122", "æ˜“æ–¹è¾¾ä¸­è¯éé“¶é‡‘è", "éé“¶é‡‘è"),
    ("164906", "äº¤é“¶ä¸­è¯æµ·å¤–äº’è”ç½‘", "ä¸­æ¦‚äº’è”"),
    ("501021", "åå®é¦™æ¸¯ä¸­å°", "æ¸¯è‚¡ä¸­å°"),
    ("160717", "å˜‰å®æ’ç”Ÿä¸­å›½ä¼ä¸š", "æ’ç”Ÿå›½ä¼"),
    ("164824", "å°åº¦åŸºé‡‘", "å°åº¦å¸‚åœº"),
    ("164701", "æ±‡æ·»å¯Œæ’ç”ŸæŒ‡æ•°", "æ’ç”ŸæŒ‡æ•°"),
    ("501018", "å—æ–¹åŸæ²¹", "åŸæ²¹"),
    ("506000", "ç§‘åˆ›æ¿åŸºé‡‘", "ç§‘åˆ›æ¿"),
    ("506002", "æ˜“æ–¹è¾¾ç§‘åˆ›æ¿", "ç§‘åˆ›æ¿"),
    ("162411", "åå®æ²¹æ°”LOF", "æ²¹æ°”"),
]

# ==========================================
# ğŸ”‘ åŸºé‡‘åˆ†ç±»åŠæº¢ä»·é˜ˆå€¼é…ç½®
# ==========================================
# ä¸åŒç±»å‹LOFçš„æ­£å¸¸æŠ˜æº¢ä»·èŒƒå›´å®Œå…¨ä¸åŒï¼š
# - Aè‚¡å®½åŸºï¼šæµåŠ¨æ€§å¥½ï¼Œå¥—åˆ©æ´»è·ƒï¼Œ1%å°±æ˜¯å¼‚å¸¸
# - è¡Œä¸š/ä¸»é¢˜ï¼šæ³¢åŠ¨å¤§ï¼Œ1.5%æ‰ç®—å¼‚å¸¸
# - QDII/æ¸¯è‚¡ï¼šæœ‰æ±‡ç‡ã€æ—¶å·®å› ç´ ï¼Œ2-3%æ˜¯æ—¥å¸¸
# - å•†å“/åŸæ²¹ï¼šæ³¢åŠ¨æå¤§ï¼Œ5%æ‰ç®—å¼‚å¸¸

# åŸºé‡‘ç±»å‹å…³é”®è¯è¯†åˆ«
FUND_TYPE_KEYWORDS = {
    # Aè‚¡å®½åŸºLOF - é˜ˆå€¼æœ€ä½ï¼Œ1%å°±å¾ˆå¼‚å¸¸
    'a_stock_broad': {
        'keywords': ['æ²ªæ·±300', 'ä¸­è¯500', 'ä¸­è¯1000', 'ä¸Šè¯50', 'åˆ›ä¸šæ¿', 'ç§‘åˆ›æ¿', 
                     'åŸºæœ¬é¢50', 'çº¢åˆ©', 'ä»·å€¼', 'æˆé•¿', 'ä¸­å°ç›˜', 'å¤§ç›˜'],
        'threshold': 1.0,
        'type_name': 'Aè‚¡å®½åŸº',
    },
    # Aè‚¡è¡Œä¸š/ä¸»é¢˜LOF - æ³¢åŠ¨è¾ƒå¤§ï¼Œ1.5%
    'a_stock_sector': {
        'keywords': ['ç™½é…’', 'åŒ»è¯', 'æ¶ˆè´¹', 'ç§‘æŠ€', 'æ–°èƒ½æº', 'å†›å·¥', 'å›½é˜²', 'é“¶è¡Œ', 
                     'è¯åˆ¸', 'éé“¶', 'é‡‘è', 'åœ°äº§', 'ç…¤ç‚­', 'é’¢é“', 'æœ‰è‰²', 'åŒ–å·¥',
                     'ç¯ä¿', 'ä¼ åª’', 'äº’è”ç½‘', 'èŠ¯ç‰‡', 'åŠå¯¼ä½“', 'å…‰ä¼', 'ç”µæ± '],
        'threshold': 1.5,
        'type_name': 'Aè‚¡è¡Œä¸š',
    },
    # æ¸¯è‚¡/QDII LOF - æœ‰æ—¶å·®å’Œæ±‡ç‡å› ç´ ï¼Œ3%
    'hk_qdii': {
        'keywords': ['æ’ç”Ÿ', 'æ¸¯è‚¡', 'é¦™æ¸¯', 'ä¸­æ¦‚', 'æµ·å¤–', 'Hè‚¡', 'å›½ä¼æŒ‡æ•°'],
        'threshold': 3.0,
        'type_name': 'QDIIæ¸¯è‚¡',
    },
    # ç¾è‚¡/å…¨çƒ QDII - æ—¶å·®æ›´å¤§ï¼Œ4%
    'us_global': {
        'keywords': ['çº³æ–¯è¾¾å…‹', 'æ ‡æ™®', 'ç¾å›½', 'å…¨çƒ', 'å°åº¦', 'å¾·å›½', 'æ—¥æœ¬', 'è¶Šå—'],
        'threshold': 4.0,
        'type_name': 'QDIIå…¨çƒ',
    },
    # å•†å“/åŸæ²¹ - æ³¢åŠ¨æå¤§ï¼Œ5%
    'commodity': {
        'keywords': ['åŸæ²¹', 'æ²¹æ°”', 'é»„é‡‘', 'ç™½é“¶', 'å•†å“', 'èƒ½æº'],
        'threshold': 5.0,
        'type_name': 'å•†å“åŸæ²¹',
    },
}

# é»˜è®¤é˜ˆå€¼ï¼ˆæœªè¯†åˆ«ç±»å‹ï¼‰
DEFAULT_THRESHOLD = 2.0


# æœ€ä½æˆäº¤é¢é˜ˆå€¼ï¼ˆä¸‡å…ƒï¼‰- ä½äºæ­¤å€¼å¥—åˆ©æ— æ„ä¹‰
MIN_AMOUNT_THRESHOLD = 500  # 500ä¸‡


# ==========================================
# ğŸ• äº¤æ˜“æ—¶æ®µé…ç½®ï¼ˆç”¨äºIOPVå¯ä¿¡åº¦åˆ¤æ–­ï¼‰
# ==========================================
# Aè‚¡äº¤æ˜“æ—¶é—´: 09:30-11:30, 13:00-15:00
# æ¸¯è‚¡äº¤æ˜“æ—¶é—´: 09:30-12:00, 13:00-16:00
# ç¾è‚¡äº¤æ˜“æ—¶é—´: 21:30-04:00 (åŒ—äº¬æ—¶é—´ï¼Œå¤ä»¤æ—¶)
#              22:30-05:00 (åŒ—äº¬æ—¶é—´ï¼Œå†¬ä»¤æ—¶)

def get_current_hour():
    """è·å–å½“å‰å°æ—¶ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰"""
    return datetime.now().hour


def is_hk_market_open():
    """æ¸¯è‚¡æ˜¯å¦åœ¨äº¤æ˜“æ—¶æ®µ"""
    hour = get_current_hour()
    # æ¸¯è‚¡ 09:30-12:00, 13:00-16:00
    return (9 <= hour < 12) or (13 <= hour < 16)


def is_us_market_open():
    """ç¾è‚¡æ˜¯å¦åœ¨äº¤æ˜“æ—¶æ®µï¼ˆç²—ç•¥åˆ¤æ–­ï¼‰"""
    hour = get_current_hour()
    # ç¾è‚¡å¤ä»¤æ—¶ 21:30-04:00ï¼Œå†¬ä»¤æ—¶ 22:30-05:00
    # ç®€åŒ–åˆ¤æ–­ï¼š21:00-05:00 è®¤ä¸ºå¯èƒ½å¼€ç›˜
    return hour >= 21 or hour < 5


# ==========================================
# ğŸ“Š èµ„é‡‘æ•ˆç‡é…ç½®
# ==========================================
# ä¸åŒç±»å‹LOFçš„ç»“ç®—å‘¨æœŸ
SETTLEMENT_DAYS = {
    'Aè‚¡å®½åŸº': 2,      # T+2
    'Aè‚¡è¡Œä¸š': 2,      # T+2
    'QDIIæ¸¯è‚¡': 3,     # T+3 (éƒ¨åˆ†T+2)
    'QDIIå…¨çƒ': 4,     # T+4 (ç¾è‚¡ç­‰)
    'å•†å“åŸæ²¹': 3,     # T+3
    'å…¶ä»–': 2,
}


def classify_fund(name):
    """
    æ ¹æ®åŸºé‡‘åç§°è¯†åˆ«åŸºé‡‘ç±»å‹ï¼Œè¿”å›(ç±»å‹åç§°, æº¢ä»·é˜ˆå€¼, ç»“ç®—å¤©æ•°)
    ä¼˜å…ˆçº§ï¼šå•†å“ > QDIIå…¨çƒ > QDIIæ¸¯è‚¡ > Aè‚¡è¡Œä¸š > Aè‚¡å®½åŸº
    """
    name_lower = name.lower()
    
    # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥ï¼ˆç‰¹æ®Šç±»å‹ä¼˜å…ˆï¼‰
    priority_order = ['commodity', 'us_global', 'hk_qdii', 'a_stock_sector', 'a_stock_broad']
    
    for fund_type in priority_order:
        config = FUND_TYPE_KEYWORDS[fund_type]
        for keyword in config['keywords']:
            if keyword in name or keyword.lower() in name_lower:
                type_name = config['type_name']
                return type_name, config['threshold'], SETTLEMENT_DAYS.get(type_name, 2)
    
    return 'å…¶ä»–', DEFAULT_THRESHOLD, 2


def calculate_iopv_reliability(fund_type, est_change_pct):
    """
    è®¡ç®—IOPVå¯ä¿¡åº¦ï¼ˆç®€åŒ–ç‰ˆï¼Œå‡å°‘è¿‡åº¦è­¦å‘Šï¼‰
    
    æ ¸å¿ƒåŸåˆ™ï¼š
    - Aè‚¡ç±»å‹ï¼šIOPVåŸºæœ¬å¯é ï¼Œä¸éœ€è¦è¿‡åº¦è­¦å‘Š
    - QDIIç±»å‹ï¼šä»…åœ¨æç«¯æƒ…å†µä¸‹ç»™å‡ºè­¦å‘Š
    
    è¿”å›: (reliability: 'high'|'medium'|'low', reason: str)
    """
    est_change = abs(est_change_pct) if est_change_pct else 0
    
    # Aè‚¡ç±»å‹ï¼šIOPVå¯ä¿¡åº¦é«˜ï¼ˆæ— è®ºç›˜ä¸­è¿˜æ˜¯æ”¶ç›˜åï¼‰
    if fund_type in ['Aè‚¡å®½åŸº', 'Aè‚¡è¡Œä¸š']:
        return 'high', 'Aè‚¡IOPVè·Ÿè¸ªå‡†ç¡®'
    
    # æ¸¯è‚¡QDII - ä»…åœ¨æç«¯æ³¢åŠ¨æ—¶è­¦å‘Š
    if fund_type == 'QDIIæ¸¯è‚¡':
        if est_change > 5:
            return 'medium', f'æ¸¯è‚¡ä¼°å€¼æ³¢åŠ¨è¾ƒå¤§({est_change:.1f}%)'
        return 'high', 'æ¸¯è‚¡IOPV'
    
    # ç¾è‚¡/å…¨çƒQDII - ä»…åœ¨æç«¯æ³¢åŠ¨æ—¶è­¦å‘Š
    if fund_type == 'QDIIå…¨çƒ':
        if est_change > 5:
            return 'medium', f'å…¨çƒå¸‚åœºä¼°å€¼æ³¢åŠ¨({est_change:.1f}%)'
        return 'high', 'å…¨çƒIOPV'
    
    # å•†å“åŸæ²¹ - æ³¢åŠ¨å¤§æ—¶è­¦å‘Š
    if fund_type == 'å•†å“åŸæ²¹':
        if est_change > 5:
            return 'medium', f'å•†å“ç±»æ³¢åŠ¨({est_change:.1f}%)'
        return 'high', 'å•†å“IOPV'
    
    return 'high', 'IOPV'


def determine_arb_path(discount, threshold, can_subscribe, fund_type, iopv_reliability):
    """
    åˆ¤æ–­å¥—åˆ©è·¯å¾„ï¼ˆç®€åŒ–ç‰ˆï¼‰
    
    æ ¸å¿ƒåŒºåˆ†ï¼š
    1. in_to_out: åœºå†…å–å‡º + åœºå¤–ç”³è´­ â†’ å¯å¥—åˆ©
    2. price_reversion: å•çº¯èµŒä»·æ ¼å›å½’ â†’ æ— æ³•ç”³è´­
    3. none: æœªè¾¾é˜ˆå€¼
    
    è¿”å›: (arb_path, arb_path_desc)
    """
    if discount < threshold:
        return 'none', 'æœªè¾¾å¥—åˆ©é˜ˆå€¼'
    
    if can_subscribe:
        return 'in_to_out', 'åœºå†…â†’åœºå¤–å¥—åˆ©ï¼ˆç»å…¸LOFå¥—åˆ©ï¼‰'
    else:
        return 'price_reversion', 'ä»·æ ¼å›å½’åšå¼ˆï¼ˆæ— æ³•ç”³è´­ï¼Œéæ— é£é™©å¥—åˆ©ï¼‰'


def calculate_capital_efficiency(discount, settlement_days, fund_type):
    """
    è®¡ç®—èµ„é‡‘æ•ˆç‡è¯„åˆ†
    
    å¥—åˆ©ä¸æ˜¯çœ‹ç™¾åˆ†æ¯”ï¼Œè€Œæ˜¯çœ‹ï¼šå¹´åŒ–æ”¶ç›Š Ã— å‘¨è½¬ç‡ Ã— èµ„é‡‘å ç”¨
    
    å…¬å¼ï¼šå¹´åŒ–æ”¶ç›Šç‡ = æº¢ä»·ç‡ / ç»“ç®—å¤©æ•° Ã— 365
    è¯„åˆ†ï¼š0-100ï¼Œè€ƒè™‘æ”¶ç›Šç‡å’Œå‘¨è½¬æ•ˆç‡
    """
    if discount <= 0 or settlement_days <= 0:
        return 0, 0
    
    # å¹´åŒ–æ”¶ç›Šç‡ï¼ˆç®€åŒ–è®¡ç®—ï¼Œä¸è€ƒè™‘å¤åˆ©ï¼‰
    annualized_return = (discount / settlement_days) * 365
    
    # è¯„åˆ†é€»è¾‘ï¼š
    # - å¹´åŒ– > 100%: æ»¡åˆ†100
    # - å¹´åŒ– 50-100%: 80-100
    # - å¹´åŒ– 20-50%: 60-80
    # - å¹´åŒ– 10-20%: 40-60
    # - å¹´åŒ– < 10%: 0-40
    
    if annualized_return >= 100:
        score = 100
    elif annualized_return >= 50:
        score = 80 + (annualized_return - 50) / 50 * 20
    elif annualized_return >= 20:
        score = 60 + (annualized_return - 20) / 30 * 20
    elif annualized_return >= 10:
        score = 40 + (annualized_return - 10) / 10 * 20
    else:
        score = annualized_return / 10 * 40
    
    return round(annualized_return, 1), round(score, 0)


def generate_risk_notes(fund_type, iopv_reliability, est_change_pct, discount, settlement_days):
    """
    ç”Ÿæˆé£é™©æç¤ºï¼ˆç²¾ç®€ç‰ˆï¼Œåªæç¤ºå…³é”®é£é™©ï¼‰
    """
    notes = []
    
    # åªåœ¨ç»“ç®—å‘¨æœŸé•¿æ—¶æç¤º
    if settlement_days >= 4:
        notes.append(f'â° T+{settlement_days}ç»“ç®—ï¼Œèµ„é‡‘å ç”¨è¾ƒé•¿')
    
    # åªåœ¨æ³¢åŠ¨ç‰¹åˆ«å¤§æ—¶æç¤º
    if est_change_pct and abs(est_change_pct) > 3:
        direction = 'ä¸Šæ¶¨' if est_change_pct > 0 else 'ä¸‹è·Œ'
        notes.append(f'ğŸ“ˆ ä»Šæ—¥ä¼°å€¼{direction}{abs(est_change_pct):.1f}%')
    
    return notes


def get_realtime_estimation():
    """
    è·å–åŸºé‡‘å®æ—¶ä¼°å€¼æ•°æ®
    è¿™æ˜¯ç›˜ä¸­æ ¹æ®æŒä»“å’ŒæŒ‡æ•°æ¶¨è·Œä¼°ç®—çš„å‡€å€¼ï¼Œè€ŒéT-1å…¬å¸ƒå‡€å€¼
    """
    print("ğŸ“Š è·å–åŸºé‡‘å®æ—¶ä¼°å€¼ï¼ˆç›˜ä¸­IOPVä¼°ç®—ï¼‰...")
    
    try:
        df = ak.fund_value_estimation_em(symbol="å…¨éƒ¨")
        
        if df is None or df.empty:
            print("âŒ è·å–å®æ—¶ä¼°å€¼å¤±è´¥")
            return None
        
        # åŠ¨æ€è·å–åˆ—åï¼ˆåŒ…å«æ—¥æœŸï¼‰
        est_col = [c for c in df.columns if 'ä¼°ç®—å€¼' in c][0]
        est_rate_col = [c for c in df.columns if 'ä¼°ç®—å¢é•¿ç‡' in c][0]
        prev_nav_cols = [c for c in df.columns if 'å•ä½å‡€å€¼' in c and 'å…¬å¸ƒ' not in c]
        prev_nav_col = prev_nav_cols[-1] if prev_nav_cols else None
        
        result = pd.DataFrame({
            'code': df['åŸºé‡‘ä»£ç '].astype(str),
            'name': df['åŸºé‡‘åç§°'],
            'est_nav': pd.to_numeric(df[est_col], errors='coerce'),  # å®æ—¶ä¼°ç®—å‡€å€¼
            'est_change_pct': df[est_rate_col].str.replace('%', '').astype(float, errors='ignore'),
            'prev_nav': pd.to_numeric(df[prev_nav_col], errors='coerce') if prev_nav_col else None,
        })
        
        print(f"âœ… è·å–åˆ° {len(result)} åªåŸºé‡‘å®æ—¶ä¼°å€¼")
        return result
        
    except Exception as e:
        print(f"âŒ è·å–å®æ—¶ä¼°å€¼å¤±è´¥: {e}")
        return None


def get_lof_spot():
    """è·å–LOFåŸºé‡‘å®æ—¶è¡Œæƒ…ï¼ˆåœºå†…ä»·æ ¼ï¼‰"""
    print("ğŸ“Š è·å–LOFåŸºé‡‘åœºå†…å®æ—¶è¡Œæƒ…...")
    
    try:
        df = ak.fund_lof_spot_em()
        
        if df is None or df.empty:
            print("âŒ è·å–LOFå®æ—¶è¡Œæƒ…å¤±è´¥")
            return None
        
        result = pd.DataFrame({
            'code': df['ä»£ç '].astype(str),
            'name': df['åç§°'],
            'price': pd.to_numeric(df['æœ€æ–°ä»·'], errors='coerce'),
            'change_pct': pd.to_numeric(df['æ¶¨è·Œå¹…'], errors='coerce'),
            'volume': pd.to_numeric(df['æˆäº¤é‡'], errors='coerce'),
            'amount': pd.to_numeric(df['æˆäº¤é¢'], errors='coerce'),
            'turnover_rate': pd.to_numeric(df['æ¢æ‰‹ç‡'], errors='coerce'),
            'prev_close': pd.to_numeric(df['æ˜¨æ”¶'], errors='coerce'),
        })
        
        print(f"âœ… è·å–åˆ° {len(result)} åªLOFåŸºé‡‘è¡Œæƒ…")
        return result
        
    except Exception as e:
        print(f"âŒ è·å–LOFå®æ—¶è¡Œæƒ…å¤±è´¥: {e}")
        return None


def get_fund_subscribe_status():
    """
    è·å–åŸºé‡‘ç”³è´­çŠ¶æ€
    è¿™æ˜¯å¥—åˆ©çš„ç”Ÿæ­»çº¿ï¼80%çš„LOFæº¢ä»· = ç”³è´­æš‚åœï¼Œæ°¸è¿œæ— æ³•å¥—åˆ©
    """
    print("ğŸ“Š è·å–åŸºé‡‘ç”³è´­çŠ¶æ€...")
    
    try:
        df = ak.fund_purchase_em()
        
        if df is None or df.empty:
            print("âŒ è·å–ç”³è´­çŠ¶æ€å¤±è´¥")
            return {}
        
        # æ„å»ºç”³è´­çŠ¶æ€å­—å…¸
        # ç”³è´­çŠ¶æ€: å¼€æ”¾ç”³è´­ã€æš‚åœç”³è´­ã€é™å¤§é¢ã€å°é—­æœŸã€è®¤è´­æœŸã€åœºå†…äº¤æ˜“
        status_dict = {}
        for _, row in df.iterrows():
            code = str(row['åŸºé‡‘ä»£ç '])
            subscribe_status = row['ç”³è´­çŠ¶æ€']
            redeem_status = row['èµå›çŠ¶æ€']
            daily_limit = row['æ—¥ç´¯è®¡é™å®šé‡‘é¢']  # é™é¢ï¼ˆä¸‡å…ƒï¼‰
            
            # åˆ¤æ–­æ˜¯å¦å¯ç”³è´­
            # å¼€æ”¾ç”³è´­ / é™å¤§é¢ = å¯ä»¥ç”³è´­ï¼ˆé™å¤§é¢å¯¹æ•£æˆ·å½±å“ä¸å¤§ï¼‰
            # æš‚åœç”³è´­ / å°é—­æœŸ / è®¤è´­æœŸ = ä¸å¯ç”³è´­
            can_subscribe = subscribe_status in ['å¼€æ”¾ç”³è´­', 'é™å¤§é¢']
            
            # å¤„ç†é™é¢ï¼šakshareè¿”å›çš„å•ä½æ˜¯ã€å…ƒã€‘
            # è¶…è¿‡10äº¿è§†ä¸ºæ— é™é¢ï¼ˆakshareè¿”å›1e11è¡¨ç¤ºæ— é™é¢ï¼‰
            limit_value = float(daily_limit) if pd.notna(daily_limit) else None
            if limit_value and limit_value >= 1e9:  # è¶…è¿‡10äº¿è§†ä¸ºæ— é™é¢
                limit_value = None
            
            status_dict[code] = {
                'subscribe_status': subscribe_status,
                'redeem_status': redeem_status,
                'can_subscribe': can_subscribe,
                'daily_limit': limit_value,  # å•ä½ï¼šå…ƒ
            }
        
        open_count = sum(1 for v in status_dict.values() if v['can_subscribe'])
        print(f"âœ… è·å–åˆ° {len(status_dict)} åªåŸºé‡‘ç”³è´­çŠ¶æ€ï¼Œå…¶ä¸­ {open_count} åªå¯ç”³è´­")
        return status_dict
        
    except Exception as e:
        print(f"âŒ è·å–ç”³è´­çŠ¶æ€å¤±è´¥: {e}")
        return {}


def calculate_realtime_arbitrage(spot_df, est_df, subscribe_status):
    """
    è®¡ç®—çœŸå®å¥—åˆ©æŠ˜æº¢ä»·ç‡
    æ ¸å¿ƒå…¬å¼ï¼š(åœºå†…ä»·æ ¼ - å®æ—¶ä¼°å€¼) / å®æ—¶ä¼°å€¼ Ã— 100%
    
    é‡è¦æ”¹è¿›ï¼š
    1. ä¸åŒç±»å‹åŸºé‡‘ä½¿ç”¨ä¸åŒé˜ˆå€¼
    2. åˆ¤æ–­ç”³è´­çŠ¶æ€ï¼ˆå¥—åˆ©ç”Ÿæ­»çº¿ï¼ï¼‰
    3. IOPVå¯ä¿¡åº¦è¯„åˆ†ï¼ˆQDIIåœ¨éäº¤æ˜“æ—¶æ®µIOPVå¤±çœŸï¼‰
    4. åŒºåˆ†å¥—åˆ©è·¯å¾„ï¼ˆåœºå†…â†’åœºå¤– vs ä»·æ ¼å›å½’åšå¼ˆï¼‰
    5. èµ„é‡‘æ•ˆç‡è¯„åˆ†ï¼ˆå¹´åŒ–æ”¶ç›Šè€ƒè™‘ç»“ç®—å‘¨æœŸï¼‰
    6. é£é™©æç¤ºï¼ˆç”³è´­ç¡®è®¤ä»·â‰ IOPVï¼‰
    """
    print("\nğŸ“ˆ è®¡ç®—å®æ—¶å¥—åˆ©æŠ˜æº¢ä»·ç‡...")
    
    # åˆå¹¶æ•°æ®
    merged = spot_df.merge(
        est_df[['code', 'est_nav', 'est_change_pct', 'prev_nav']], 
        on='code', 
        how='left'
    )
    
    # å¯¹äºæ²¡æœ‰å®æ—¶ä¼°å€¼çš„LOFï¼Œå°è¯•ä»ç¼“å­˜è·å–T-1å‡€å€¼
    missing_nav_codes = merged[merged['est_nav'].isna() & merged['price'].notna()]['code'].tolist()
    if missing_nav_codes:
        print(f"  ğŸ“Œ {len(missing_nav_codes)} åªLOFæ²¡æœ‰å®æ—¶ä¼°å€¼ï¼Œå°è¯•è·å–T-1å‡€å€¼...")
        
        # åŠ è½½T-1å‡€å€¼ç¼“å­˜
        nav_cache = load_cache(NAV_CACHE_FILE)
        today = get_today_str()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦æ˜¯ä»Šå¤©çš„
        cache_date = nav_cache.get('_date', '')
        if cache_date != today:
            nav_cache = {'_date': today}  # é‡ç½®ç¼“å­˜
        
        codes_to_fetch = []
        for code in missing_nav_codes[:30]:
            if code in nav_cache:
                # ä½¿ç”¨ç¼“å­˜
                latest_nav = nav_cache[code]
                merged.loc[merged['code'] == code, 'est_nav'] = latest_nav
                merged.loc[merged['code'] == code, 'prev_nav'] = latest_nav
                print(f"    âœ“ {code} T-1å‡€å€¼(ç¼“å­˜): {latest_nav}")
            else:
                codes_to_fetch.append(code)
        
        # åªè¯·æ±‚æœªç¼“å­˜çš„
        if codes_to_fetch:
            print(f"    ğŸ“¡ éœ€è¦è¯·æ±‚ {len(codes_to_fetch)} åªåŸºé‡‘çš„T-1å‡€å€¼...")
            for code in codes_to_fetch:
                try:
                    nav_df = ak.fund_open_fund_info_em(symbol=code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
                    if nav_df is not None and not nav_df.empty:
                        latest_nav = float(nav_df.iloc[-1]['å•ä½å‡€å€¼'])
                        merged.loc[merged['code'] == code, 'est_nav'] = latest_nav
                        merged.loc[merged['code'] == code, 'prev_nav'] = latest_nav
                        nav_cache[code] = latest_nav  # å†™å…¥ç¼“å­˜
                        print(f"    âœ“ {code} T-1å‡€å€¼(API): {latest_nav}")
                except Exception as e:
                    pass
                time.sleep(0.1)
            
            # ä¿å­˜ç¼“å­˜
            save_cache(NAV_CACHE_FILE, nav_cache)
    
    # è®¡ç®—å®æ—¶æŠ˜æº¢ä»·ç‡ï¼ˆæ ¸å¿ƒï¼ï¼‰
    merged['realtime_discount'] = (merged['price'] - merged['est_nav']) / merged['est_nav'] * 100
    
    # åŒæ—¶ä¿ç•™T-1å‡€å€¼æŠ˜æº¢ä»·ï¼ˆç”¨äºå¯¹æ¯”å±•ç¤ºï¼‰
    merged['t1_discount'] = (merged['price'] - merged['prev_nav']) / merged['prev_nav'] * 100
    
    # ç­›é€‰æœ‰æ•ˆæ•°æ®
    valid = merged[
        merged['price'].notna() & 
        merged['est_nav'].notna() & 
        (merged['est_nav'] > 0) &
        (merged['price'] > 0)
    ].copy()
    
    # åˆ¤æ–­å¥—åˆ©ä¿¡å·ï¼ˆåŸºäºå®æ—¶æŠ˜æº¢ä»·ï¼Œä½¿ç”¨åˆ†ç±»é˜ˆå€¼ï¼‰
    def get_signal(row):
        discount = row['realtime_discount']
        name = row['name']
        code = row['code']
        est_change_pct = row['est_change_pct'] if pd.notna(row['est_change_pct']) else 0
        amount = row['amount'] / 10000 if pd.notna(row['amount']) else 0  # è½¬ä¸ºä¸‡å…ƒ
        
        if pd.isna(discount):
            return (None, 0, 'å…¶ä»–', DEFAULT_THRESHOLD, False, '', '', True,
                    'medium', '', 'none', '', 2, 0, 0, [], None)
        
        # è·å–åŸºé‡‘ç±»å‹ã€é˜ˆå€¼å’Œç»“ç®—å¤©æ•°
        fund_type, threshold, settlement_days = classify_fund(name)
        
        # è·å–ç”³è´­çŠ¶æ€
        status_info = subscribe_status.get(code, {})
        can_subscribe = status_info.get('can_subscribe', True)  # é»˜è®¤å¯ç”³è´­ï¼ˆæœªæŸ¥åˆ°çŠ¶æ€ï¼‰
        subscribe_status_text = status_info.get('subscribe_status', 'æœªçŸ¥')
        redeem_status_text = status_info.get('redeem_status', 'æœªçŸ¥')
        daily_limit = status_info.get('daily_limit', None)  # é™é¢ï¼ˆä¸‡å…ƒï¼‰
        
        # æµåŠ¨æ€§åˆ¤æ–­ï¼šæˆäº¤é¢ < 500ä¸‡ = æµåŠ¨æ€§ä¸è¶³
        low_liquidity = amount < MIN_AMOUNT_THRESHOLD
        
        # ğŸ†• IOPVå¯ä¿¡åº¦è¯„åˆ†
        iopv_reliability, iopv_reason = calculate_iopv_reliability(fund_type, est_change_pct)
        
        # ğŸ†• å¥—åˆ©è·¯å¾„åˆ¤æ–­
        arb_path, arb_path_desc = determine_arb_path(discount, threshold, can_subscribe, fund_type, iopv_reliability)
        
        # ğŸ†• èµ„é‡‘æ•ˆç‡è¯„åˆ†
        annualized_return, capital_efficiency = calculate_capital_efficiency(discount, settlement_days, fund_type)
        
        # ğŸ†• é£é™©æç¤º
        risk_notes = generate_risk_notes(fund_type, iopv_reliability, est_change_pct, discount, settlement_days)
        
        # æº¢ä»·è¶…è¿‡è¯¥ç±»å‹é˜ˆå€¼æ‰ç®—å¥—åˆ©æœºä¼š
        if discount >= threshold:
            # ä¿¡å·å¼ºåº¦ï¼šè¶…è¿‡é˜ˆå€¼çš„å€æ•°
            excess = discount - threshold
            strength = min((excess / threshold) * 100, 100)
            return ("æº¢ä»·å¥—åˆ©", round(strength, 1), fund_type, threshold, can_subscribe, 
                    subscribe_status_text, redeem_status_text, low_liquidity,
                    iopv_reliability, iopv_reason, arb_path, arb_path_desc,
                    settlement_days, annualized_return, capital_efficiency, risk_notes, daily_limit)
        
        return (None, 0, fund_type, threshold, can_subscribe, 
                subscribe_status_text, redeem_status_text, low_liquidity,
                iopv_reliability, iopv_reason, arb_path, arb_path_desc,
                settlement_days, annualized_return, capital_efficiency, risk_notes, daily_limit)
    
    signals = valid.apply(get_signal, axis=1, result_type='expand')
    valid['signal_type'] = signals[0]
    valid['signal_strength'] = signals[1]
    valid['fund_type'] = signals[2]
    valid['threshold'] = signals[3]
    valid['can_subscribe'] = signals[4]
    valid['subscribe_status'] = signals[5]
    valid['redeem_status'] = signals[6]
    valid['low_liquidity'] = signals[7]
    valid['iopv_reliability'] = signals[8]
    valid['iopv_reason'] = signals[9]
    valid['arb_path'] = signals[10]
    valid['arb_path_desc'] = signals[11]
    valid['settlement_days'] = signals[12]
    valid['annualized_return'] = signals[13]
    valid['capital_efficiency'] = signals[14]
    valid['risk_notes'] = signals[15]
    valid['daily_limit'] = signals[16]
    
    # æ„å»ºç»“æœ
    results = []
    for _, row in valid.iterrows():
        results.append({
            'code': row['code'],
            'name': row['name'],
            'price': round(row['price'], 4),
            'est_nav': round(row['est_nav'], 4),
            'prev_nav': round(row['prev_nav'], 4) if pd.notna(row['prev_nav']) else None,
            'realtime_discount': round(row['realtime_discount'], 2),
            't1_discount': round(row['t1_discount'], 2) if pd.notna(row['t1_discount']) else None,
            'est_change_pct': round(row['est_change_pct'], 2) if pd.notna(row['est_change_pct']) else None,
            'change_pct': round(row['change_pct'], 2) if pd.notna(row['change_pct']) else None,
            'volume': int(row['volume']) if pd.notna(row['volume']) else 0,
            'amount': round(row['amount'] / 10000, 2) if pd.notna(row['amount']) else 0,
            'turnover_rate': round(row['turnover_rate'], 2) if pd.notna(row['turnover_rate']) else None,
            'signal_type': row['signal_type'],
            'signal_strength': row['signal_strength'],
            'fund_type': row['fund_type'],
            'threshold': row['threshold'],
            'can_subscribe': row['can_subscribe'],
            'subscribe_status': row['subscribe_status'],
            'redeem_status': row['redeem_status'],
            'low_liquidity': row['low_liquidity'],
            'daily_limit': float(row['daily_limit']) if pd.notna(row['daily_limit']) else None,  # é™é¢ï¼ˆå…ƒï¼‰
            # å…¶ä»–å­—æ®µ
            'iopv_reliability': row['iopv_reliability'],
            'iopv_reason': row['iopv_reason'],
            'arb_path': row['arb_path'],
            'arb_path_desc': row['arb_path_desc'],
            'settlement_days': row['settlement_days'],
            'annualized_return': row['annualized_return'],
            'capital_efficiency': row['capital_efficiency'],
            'risk_notes': row['risk_notes'],
        })
    
    print(f"âœ… è®¡ç®—å®Œæˆï¼Œæœ‰æ•ˆæ•°æ® {len(results)} åª")
    return results


def get_fund_nav_history(fund_code, days=60, cache=None):
    """è·å–åŸºé‡‘å†å²å‡€å€¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # å¦‚æœæœ‰ç¼“å­˜ä¸”æ•°æ®è¶³å¤Ÿæ–°ï¼Œç›´æ¥è¿”å›
    if cache and fund_code in cache:
        cached_data = cache[fund_code]
        if cached_data:
            return cached_data
    
    try:
        df = ak.fund_open_fund_info_em(symbol=fund_code, indicator="å•ä½å‡€å€¼èµ°åŠ¿")
        if df is not None and not df.empty:
            df = df.tail(days)
            result = [
                {'date': str(row['å‡€å€¼æ—¥æœŸ'])[:10], 'nav': float(row['å•ä½å‡€å€¼'])}
                for _, row in df.iterrows()
            ]
            return result
    except:
        pass
    return []


def get_fund_price_history(fund_code, days=60, cache=None):
    """è·å–LOFåŸºé‡‘å†å²ä»·æ ¼ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    # å¦‚æœæœ‰ç¼“å­˜ä¸”æ•°æ®è¶³å¤Ÿæ–°ï¼Œç›´æ¥è¿”å›
    if cache and fund_code in cache:
        cached_data = cache[fund_code]
        if cached_data:
            return cached_data
    
    try:
        df = ak.fund_lof_hist_em(symbol=fund_code, period="daily", adjust="")
        if df is not None and not df.empty:
            df = df.tail(days)
            result = [
                {
                    'date': str(row['æ—¥æœŸ'])[:10],
                    'close': float(row['æ”¶ç›˜']),
                    'volume': int(row['æˆäº¤é‡']),
                }
                for _, row in df.iterrows()
            ]
            return result
    except:
        pass
    return []


def get_hot_lof_details(all_funds):
    """è·å–çƒ­é—¨LOFåŸºé‡‘è¯¦æƒ…ï¼ˆå¸¦æ™ºèƒ½ç¼“å­˜ï¼‰"""
    print("\nğŸ“ˆ è·å–çƒ­é—¨LOFåŸºé‡‘å†å²æ•°æ®...")
    
    hot_codes = {code for code, _, _ in HOT_LOF_LIST}
    hot_map = {code: (name, track) for code, name, track in HOT_LOF_LIST}
    
    # åŠ è½½å†å²ç¼“å­˜
    nav_history_cache = load_cache(NAV_HISTORY_CACHE_FILE)
    price_history_cache = load_cache(PRICE_HISTORY_CACHE_FILE)
    
    today = get_today_str()
    
    # æ£€æŸ¥ç¼“å­˜æ˜¯å¦éœ€è¦æ›´æ–°
    # æ¡ä»¶1: æ—¥æœŸå˜åŒ–ï¼ˆæ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
    # æ¡ä»¶2: åŸºé‡‘åˆ—è¡¨å˜åŒ–ï¼ˆcodeå˜åŒ–æ—¶æ›´æ–°ï¼‰
    current_codes_hash = get_codes_hash(list(hot_codes))
    cache_date = nav_history_cache.get('_date', '')
    cache_hash = nav_history_cache.get('_codes_hash', '')
    
    need_full_refresh = (cache_date != today) or (cache_hash != current_codes_hash)
    
    if need_full_refresh:
        print(f"  ğŸ“¡ ç¼“å­˜éœ€è¦æ›´æ–° (æ—¥æœŸ:{cache_date != today}, ä»£ç å˜åŒ–:{cache_hash != current_codes_hash})")
        nav_history_cache = {'_date': today, '_codes_hash': current_codes_hash}
        price_history_cache = {'_date': today, '_codes_hash': current_codes_hash}
    else:
        print(f"  âœ… ä½¿ç”¨ä»Šæ—¥ç¼“å­˜æ•°æ®")
    
    hot_details = []
    api_calls = 0
    cache_hits = 0
    
    for fund in all_funds:
        code = fund['code']
        if code not in hot_codes:
            continue
        
        name, track_index = hot_map.get(code, (fund['name'], ''))
        
        # è·å–å†å²æ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨ç¼“å­˜ï¼‰
        if code in nav_history_cache and not need_full_refresh:
            nav_history = nav_history_cache[code]
            cache_hits += 1
        else:
            print(f"  ğŸ“¡ è·å– {code} {name} å†å²å‡€å€¼...")
            nav_history = get_fund_nav_history(code, days=60)
            nav_history_cache[code] = nav_history
            api_calls += 1
            time.sleep(0.15)
        
        if code in price_history_cache and not need_full_refresh:
            price_history = price_history_cache[code]
            cache_hits += 1
        else:
            print(f"  ğŸ“¡ è·å– {code} {name} å†å²ä»·æ ¼...")
            price_history = get_fund_price_history(code, days=60)
            price_history_cache[code] = price_history
            api_calls += 1
            time.sleep(0.15)
        
        # è®¡ç®—å†å²æŠ˜æº¢ä»·ç‡
        discount_history = []
        if price_history and nav_history:
            nav_dict = {item['date']: item['nav'] for item in nav_history}
            for price_item in price_history:
                date_str = price_item['date']
                if date_str in nav_dict and nav_dict[date_str] > 0:
                    discount = (price_item['close'] - nav_dict[date_str]) / nav_dict[date_str] * 100
                    discount_history.append({
                        'date': date_str,
                        'price': price_item['close'],
                        'nav': nav_dict[date_str],
                        'discount_rate': round(discount, 2)
                    })
        
        hot_details.append({
            **fund,
            'track_index': track_index,
            'price_history': price_history[-30:],
            'discount_history': discount_history[-30:],
        })
    
    # ä¿å­˜ç¼“å­˜
    if api_calls > 0:
        save_cache(NAV_HISTORY_CACHE_FILE, nav_history_cache)
        save_cache(PRICE_HISTORY_CACHE_FILE, price_history_cache)
        print(f"  ğŸ’¾ ç¼“å­˜å·²æ›´æ–°")
    
    print(f"âœ… è·å–åˆ° {len(hot_details)} åªçƒ­é—¨LOFè¯¦æƒ… (APIè°ƒç”¨:{api_calls}, ç¼“å­˜å‘½ä¸­:{cache_hits})")
    return hot_details


def get_arbitrage_opportunities(signals, top_n=20):
    """è·å–æº¢ä»·å¥—åˆ©æœºä¼š"""
    premium_opps = [s for s in signals if s['signal_type'] == "æº¢ä»·å¥—åˆ©"]
    premium_opps.sort(key=lambda x: x['realtime_discount'], reverse=True)
    
    return {
        'premium': premium_opps[:top_n],
    }


def get_market_overview(signals):
    """è·å–å¸‚åœºæ¦‚è§ˆ"""
    if not signals:
        return {
            'total_count': 0,
            'avg_discount_rate': 0,
            'max_discount': 0,
            'max_premium': 0,
            'distribution': {
                'deep_discount': 0, 'slight_discount': 0, 'fair_value': 0,
                'slight_premium': 0, 'deep_premium': 0,
            }
        }
    
    rates = [s['realtime_discount'] for s in signals if s['realtime_discount'] is not None]
    
    if not rates:
        return {
            'total_count': len(signals),
            'avg_discount_rate': 0,
            'max_discount': 0,
            'max_premium': 0,
            'distribution': {
                'deep_discount': 0, 'slight_discount': 0, 'fair_value': 0,
                'slight_premium': 0, 'deep_premium': 0,
            }
        }
    
    return {
        'total_count': len(signals),
        'avg_discount_rate': round(sum(rates) / len(rates), 2),
        'max_discount': round(min(rates), 2),
        'max_premium': round(max(rates), 2),
        'distribution': {
            'deep_discount': len([r for r in rates if r <= -3]),
            'slight_discount': len([r for r in rates if -3 < r <= -1]),
            'fair_value': len([r for r in rates if -1 < r < 1]),
            'slight_premium': len([r for r in rates if 1 <= r < 3]),
            'deep_premium': len([r for r in rates if r >= 3]),
        }
    }


def generate_ts_file(data):
    """ç”ŸæˆTypeScriptæ•°æ®æ–‡ä»¶"""
    ts_content = f"""// LOFåŸºé‡‘å¥—åˆ©ç›‘æµ‹æ•°æ®
// è‡ªåŠ¨ç”Ÿæˆäº {data['meta']['updated_at']}
// æ ¸å¿ƒæ”¹è¿›ï¼šä½¿ç”¨ã€ç›˜ä¸­å®æ—¶ä¼°å€¼ã€‘è®¡ç®—æŠ˜æº¢ä»·ï¼Œè€ŒéT-1å‡€å€¼

export const LOF_DATA = {json.dumps(data, ensure_ascii=False, indent=2)};

export default LOF_DATA;
"""
    
    with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
        f.write(ts_content)
    
    print(f"\nâœ… æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_PATH}")


def main():
    print("=" * 60)
    print("ğŸš€ LOFåŸºé‡‘å¥—åˆ©ç›‘æµ‹æ•°æ®è·å–")
    print("ğŸ“Œ æ ¸å¿ƒæ”¹è¿›ï¼šä½¿ç”¨ç›˜ä¸­å®æ—¶ä¼°å€¼è®¡ç®—çœŸå®å¥—åˆ©æŠ˜æº¢ä»·")
    print("ğŸ“Œ æ–°å¢ï¼šç”³è´­çŠ¶æ€åˆ¤æ–­ï¼ˆå¥—åˆ©ç”Ÿæ­»çº¿ï¼ï¼‰")
    print("=" * 60)
    
    # 1. è·å–å®æ—¶ä¼°å€¼ï¼ˆç›˜ä¸­IOPVï¼‰
    est_df = get_realtime_estimation()
    if est_df is None:
        print("âŒ è·å–å®æ—¶ä¼°å€¼å¤±è´¥ï¼Œé€€å‡º")
        sys.exit(1)
    
    # 2. è·å–LOFåœºå†…è¡Œæƒ…
    spot_df = get_lof_spot()
    if spot_df is None:
        print("âŒ è·å–LOFè¡Œæƒ…å¤±è´¥ï¼Œé€€å‡º")
        sys.exit(1)
    
    # 3. è·å–ç”³è´­çŠ¶æ€ï¼ˆå…³é”®ï¼ï¼‰
    subscribe_status = get_fund_subscribe_status()
    
    # 4. è®¡ç®—å®æ—¶å¥—åˆ©æŠ˜æº¢ä»·ï¼ˆä¼ å…¥ç”³è´­çŠ¶æ€ï¼‰
    all_funds = calculate_realtime_arbitrage(spot_df, est_df, subscribe_status)
    
    # 5. è·å–å¥—åˆ©æœºä¼š
    opportunities = get_arbitrage_opportunities(all_funds)
    
    # 6. è·å–å¸‚åœºæ¦‚è§ˆ
    overview = get_market_overview(all_funds)
    
    # 7. è·å–çƒ­é—¨LOFè¯¦æƒ…
    hot_funds = get_hot_lof_details(all_funds)
    
    # ç»„è£…æ•°æ®
    data = {
        'meta': {
            'updated_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            'desc': 'LOFåŸºé‡‘å¥—åˆ©ç›‘æµ‹æ•°æ®ï¼ˆåŸºäºç›˜ä¸­å®æ—¶ä¼°å€¼ï¼‰',
            'note': 'æŠ˜æº¢ä»·ç‡åŸºäºã€å®æ—¶ä¼°å€¼ã€‘è®¡ç®— | ç”³è´­çŠ¶æ€æ˜¯å¥—åˆ©ç”Ÿæ­»çº¿ï¼',
        },
        'overview': overview,
        'opportunities': opportunities,
        'all_funds': all_funds,
        'hot_funds': hot_funds,
    }
    
    generate_ts_file(data)
    
    # ç»Ÿè®¡å¯å¥—åˆ©æ•°é‡
    premium_opps = opportunities['premium']
    can_arb_count = sum(1 for f in premium_opps if f.get('can_subscribe', False))
    
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®æ¦‚è§ˆï¼ˆåŸºäºå®æ—¶ä¼°å€¼ï¼‰:")
    print(f"  - æ€»åŸºé‡‘æ•°: {overview['total_count']}")
    print(f"  - å¹³å‡æŠ˜æº¢ä»·ç‡: {overview['avg_discount_rate']}%")
    print(f"  - æœ€å¤§æŠ˜ä»·: {overview['max_discount']}%")
    print(f"  - æœ€å¤§æº¢ä»·: {overview['max_premium']}%")
    print(f"  - æº¢ä»·å¥—åˆ©æœºä¼š: {len(premium_opps)} åª")
    print(f"  - âš ï¸ å…¶ä¸­å¯ç”³è´­ï¼ˆçœŸæ­£å¯å¥—åˆ©ï¼‰: {can_arb_count} åª")
    print("=" * 60)


if __name__ == "__main__":
    main()
