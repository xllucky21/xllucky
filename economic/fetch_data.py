import akshare as ak
import pandas as pd
import json
import re
import os
import sys

import requests
import urllib3
import ssl
import warnings
# ==========================================
# ğŸ›¡ï¸ ç³»ç»Ÿåº•å±‚é…ç½®
# ==========================================
warnings.filterwarnings("ignore")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å…¨å±€ SSL ç¦ç”¨
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Requests ä¼ªè£…
old_request = requests.Session.request
def new_request(self, method, url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    return old_request(self, method, url, *args, **kwargs)
requests.Session.request = new_request

# ==========================================
# âš™ï¸ 1. æ ¸å¿ƒæŒ‡æ ‡é…ç½® & æ ‡ç­¾å­—å…¸
# ==========================================
# æ—¢ä½œä¸ºç†”æ–­æ£€æŸ¥åå•ï¼Œä¹Ÿä½œä¸ºå‰ç«¯æ˜¾ç¤ºçš„ Label å­—å…¸
INDICATOR_MAP = {
    # --- ä»·æ ¼ ---
    'cpi': 'å±…æ°‘æ¶ˆè´¹ä»·æ ¼æŒ‡æ•°(CPI)',
    'ppi': 'å·¥ä¸šå“å‡ºå‚ä»·æ ¼æŒ‡æ•°(PPI)',
    
    # --- è´§å¸ ---
    'm2': 'M2è´§å¸ä¾›åº”åŒæ¯”',
    'm1': 'M1è´§å¸ä¾›åº”åŒæ¯”',
    'scissors': 'M1-M2å‰ªåˆ€å·®',
    'social_financing': 'ç¤¾ä¼šèèµ„è§„æ¨¡å¢é‡',
    'lpr_1y': 'LPRåˆ©ç‡(1å¹´æœŸ)',
    'lpr_5y': 'LPRåˆ©ç‡(5å¹´æœŸ)',
    
    # --- å¢é•¿ ---
    'gdp': 'GDPåŒæ¯”å¢é€Ÿ',
    'pmi': 'åˆ¶é€ ä¸šPMI',
    'exports_yoy': 'å‡ºå£é‡‘é¢åŒæ¯”',
    
    # --- æ¶ˆè´¹ ---
    'retail_sales': 'ç¤¾æ¶ˆé›¶å”®æ€»é¢åŒæ¯”',
    
    # --- å¸‚åœº ---
    'sh_index': 'ä¸Šè¯æŒ‡æ•°ç‚¹ä½',
    'sh_index_pe': 'ä¸Šè¯æŒ‡æ•°å¸‚ç›ˆç‡(PE)',
    'sh_index_pb': 'ä¸Šè¯æŒ‡æ•°å¸‚å‡€ç‡(PB)',
    'us_bond_10y': '10å¹´æœŸç¾å€ºæ”¶ç›Šç‡',
    'cn_bond_10y': '10å¹´æœŸä¸­å€ºæ”¶ç›Šç‡',
    'bond_spread': 'ä¸­ç¾åˆ©å·®(ä¸­-ç¾)',
    'usd_cny': 'ç¾å…ƒå…‘äººæ°‘å¸æ±‡ç‡',
    'fx_reserves': 'å¤–æ±‡å‚¨å¤‡(äº¿ç¾å…ƒ)',
    'gold': 'ä¸Šæµ·é‡‘(Au99.99)',
    
    # --- ç»“æ„ ---
    'resident_leverage': 'å±…æ°‘éƒ¨é—¨æ æ†ç‡',
    'real_estate_invest': 'å›½æˆ¿æ™¯æ°”æŒ‡æ•°',
    'unemployment': 'åŸé•‡è°ƒæŸ¥å¤±ä¸šç‡'
}

# æ ¸å¿ƒæ ¡éªŒåå•
CRITICAL_KEYS = [k for k in INDICATOR_MAP.keys()]

# ==========================================
# 2. æ ¸å¿ƒå·¥å…·å‡½æ•°
# ==========================================
def clean_value(val):
    if pd.isna(val) or val == "": return None
    str_val = str(val).replace("%", "").replace(",", "").replace("äº¿", "").strip()
    try: return float(str_val)
    except: return None

def find_column(columns, keywords):
    for col in columns:
        col_lower = str(col).lower().strip()
        if all(k.lower() in col_lower for k in keywords): return col
    return None

def find_possible_columns(columns, keyword_groups):
    for group in keyword_groups:
        col = find_column(columns, group)
        if col: return col
    return None

def smart_date_parser(date_val):
    val_str = str(date_val).strip()
    if re.match(r'^\d{4}-\d{2}$', val_str): return pd.to_datetime(val_str).strftime('%Y-%m-%d')
    if re.match(r'^\d{4}-\d{2}-\d{2}$', val_str): return val_str
    if val_str.isdigit() and len(val_str) == 6: return pd.to_datetime(val_str, format='%Y%m').strftime('%Y-%m-%d')
    if re.match(r'^\d{4}\.\d{1,2}$', val_str):
        parts = val_str.split('.')
        if len(parts[1]) == 1: val_str = f"{parts[0]}.0{parts[1]}"
        return pd.to_datetime(val_str, format='%Y.%m').strftime('%Y-%m-%d')
    if 'å­£åº¦' in val_str or 'Q' in val_str:
        year_match = re.search(r'(\d{4})', val_str)
        year = year_match.group(1) if year_match else None
        md_map = {'ä¸€': '03-31', '1': '03-31', 'Q1': '03-31', 'äºŒ': '06-30', '2': '06-30', 'Q2': '06-30', 'ä¸‰': '09-30', '3': '09-30', 'Q3': '09-30', 'å››': '12-31', '4': '12-31', 'Q4': '12-31'}
        if year:
            for k, v in md_map.items():
                if k in val_str: return f"{year}-{v}"
    clean_str = val_str.replace('å¹´', '-').replace('æœˆä»½', '').replace('æœˆ', '').replace('/', '-')
    try: return pd.to_datetime(clean_str).strftime('%Y-%m-%d')
    except: return None

# ==========================================
# 3. æ•°æ®è·å–ä¸»é€»è¾‘
# ==========================================
def fetch_macro_data_v23():
    print("ğŸš€ å¯åŠ¨å…¨é‡è·å–è„šæœ¬ (v23.0 ç˜¦èº«ä¼˜åŒ–ç‰ˆ)...")
    print(f"ğŸ“¦ æ•°æ®ç»“æ„å·²ä¼˜åŒ–: ç§»é™¤å†—ä½™ label å­—æ®µ")
    print("-" * 60)
    export_data = {}

    # 1. ä»·æ ¼
    print("\n>>> [1. ä»·æ ¼ç»„]")
    try:
        df = ak.macro_china_cpi_monthly()
        col_d = find_possible_columns(df.columns, [['æ—¥æœŸ'], ['æœˆä»½']])
        col_v = find_possible_columns(df.columns, [['ä»Šå€¼'], ['CPI', 'åŒæ¯”']])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            # ç˜¦èº«å…³é”®: åªå– date å’Œ valueï¼Œä¸åŠ  label
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['cpi'] = res
            print(f"âœ… CPI: {len(res)} æ¡")
        else: raise Exception("CPIåˆ—åé”™")
    except Exception as e:
        print(f"âŒ CPIå¤±è´¥: {e}")
        export_data['cpi'] = []

    try:
        df = ak.macro_china_ppi_yearly()
        col_d = find_possible_columns(df.columns, [['æ—¥æœŸ'], ['æœˆä»½']])
        col_v = find_possible_columns(df.columns, [['ä»Šå€¼'], ['PPI', 'åŒæ¯”']])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['ppi'] = res
            print(f"âœ… PPI: {len(res)} æ¡")
        else: raise Exception("PPIåˆ—åé”™")
    except Exception as e:
        print(f"âŒ PPIå¤±è´¥: {e}")
        export_data['ppi'] = []

    # 2. è´§å¸
    print("\n>>> [2. è´§å¸ä¸åˆ©ç‡ç»„]")
    try:
        df = ak.macro_china_money_supply()
        col_d = find_possible_columns(df.columns, [['æœˆä»½'], ['æ—¥æœŸ']])
        col_m2 = find_column(df.columns, ['M2','åŒæ¯”'])
        col_m1 = find_column(df.columns, ['M1','åŒæ¯”'])
        if col_d and col_m2 and col_m1:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['m2'] = df[col_m2].apply(clean_value)
            df['m1'] = df[col_m1].apply(clean_value)
            df['sci'] = df['m1'] - df['m2']
            df = df.dropna(subset=['m2','m1','date']).sort_values('date')
            export_data['m2'] = df[['date','m2']].rename(columns={'m2':'value'}).to_dict('records')
            export_data['m1'] = df[['date','m1']].rename(columns={'m1':'value'}).to_dict('records')
            export_data['scissors'] = df[['date','sci']].rename(columns={'sci':'value'}).to_dict('records')
            print(f"âœ… M1/M2: {len(df)} æ¡")
        else: raise Exception("Moneyåˆ—åé”™")
    except Exception as e:
        print(f"âŒ M1/M2å¤±è´¥: {e}")
        export_data['m2'], export_data['m1'], export_data['scissors'] = [], [], []

    try:
        df = ak.macro_china_shrzgm()
        col_d = find_possible_columns(df.columns, [['æœˆä»½'], ['æ—¥æœŸ']])
        col_v = find_column(df.columns, ['å¢é‡'])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['social_financing'] = res
            print(f"âœ… ç¤¾èå¢é‡: {len(res)} æ¡")
        else: raise Exception("ç¤¾èåˆ—åé”™")
    except Exception as e:
        print(f"âŒ ç¤¾èå¤±è´¥: {e}")
        export_data['social_financing'] = []

    try:
        df = ak.macro_china_lpr()
        col_d = find_column(df.columns, ['æ—¥æœŸ']) or find_column(df.columns, ['TRADE_DATE'])
        col_1y = find_possible_columns(df.columns, [['1å¹´'], ['LPR1Y']])
        col_5y = find_possible_columns(df.columns, [['5å¹´'], ['LPR5Y']])
        if col_d and col_1y and col_5y:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['val_1y'] = df[col_1y].apply(clean_value)
            df['val_5y'] = df[col_5y].apply(clean_value)
            df = df.dropna(subset=['val_1y', 'val_5y', 'date']).sort_values('date')
            export_data['lpr_1y'] = df[['date', 'val_1y']].rename(columns={'val_1y':'value'}).to_dict('records')
            export_data['lpr_5y'] = df[['date', 'val_5y']].rename(columns={'val_5y':'value'}).to_dict('records')
            print(f"âœ… LPRåˆ©ç‡: {len(df)} æ¡")
        else: raise Exception("LPRåˆ—åé”™")
    except Exception as e:
        print(f"âŒ LPRåˆ©ç‡å¤±è´¥: {e}")
        export_data['lpr_1y'], export_data['lpr_5y'] = [], []

    # 3. å¢é•¿
    print("\n>>> [3. å¢é•¿ç»„]")
    try:
        df = ak.macro_china_gdp_yearly()
        col_d = find_possible_columns(df.columns, [['æ—¥æœŸ'], ['å­£åº¦']])
        col_v = find_possible_columns(df.columns, [['ä»Šå€¼'], ['å›½å†…ç”Ÿäº§æ€»å€¼','åŒæ¯”']])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['gdp'] = res
            print(f"âœ… GDP: {len(res)} æ¡")
        else: raise Exception("GDPåˆ—åé”™")
    except Exception as e:
        print(f"âŒ GDPå¤±è´¥: {e}")
        export_data['gdp'] = []

    try:
        df = ak.macro_china_pmi_yearly()
        col_d = find_column(df.columns, ['æ—¥æœŸ'])
        col_v = find_column(df.columns, ['ä»Šå€¼'])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['pmi'] = res
            print(f"âœ… PMI: {len(res)} æ¡")
        else: raise Exception("PMIåˆ—åé”™")
    except Exception as e:
        print(f"âŒ PMIå¤±è´¥: {e}")
        export_data['pmi'] = []

    try:
        df = ak.macro_china_exports_yoy()
        col_d = find_column(df.columns, ['æ—¥æœŸ'])
        col_v = find_column(df.columns, ['ä»Šå€¼'])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['exports_yoy'] = res
            print(f"âœ… å‡ºå£: {len(res)} æ¡")
        else: raise Exception("å‡ºå£åˆ—åé”™")
    except Exception as e:
        print(f"âŒ å‡ºå£å¤±è´¥: {e}")
        export_data['exports_yoy'] = []

    # 4. æ¶ˆè´¹
    print("\n>>> [4. æ¶ˆè´¹ç»„]")
    try:
        df = ak.macro_china_consumer_goods_retail()
        col_d = find_possible_columns(df.columns, [['æœˆä»½'], ['æ—¥æœŸ']])
        col_v = find_column(df.columns, ['åŒæ¯”å¢é•¿']) 
        if not col_v: col_v = find_column(df.columns, ['å½“æœˆ', 'åŒæ¯”'])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['retail_sales'] = res
            print(f"âœ… ç¤¾æ¶ˆ: {len(res)} æ¡")
        else: raise Exception("ç¤¾æ¶ˆåˆ—åé”™")
    except Exception as e:
        print(f"âŒ ç¤¾æ¶ˆå¤±è´¥: {e}")
        export_data['retail_sales'] = []
    
    # 5. å¸‚åœº
    print("\n>>> [5. å¸‚åœºä¸ä¼°å€¼ç»„]")
    try:
        df_idx = ak.stock_zh_index_daily(symbol="sh000001")
        if 'date' in df_idx.columns:
            df_idx['date'] = pd.to_datetime(df_idx['date'])
            try: df_m_idx = df_idx.resample('ME', on='date').last().reset_index()
            except: df_m_idx = df_idx.set_index('date').resample('M').last().reset_index()
            df_m_idx['date'] = df_m_idx['date'].dt.strftime('%Y-%m-%d')
            # ç§»é™¤ label
            export_data['sh_index'] = df_m_idx[['date','close']].rename(columns={'close':'value'}).to_dict('records')
            print(f"âœ… ä¸Šè¯ç‚¹ä½: {len(df_m_idx)} æ¡")
        else: export_data['sh_index'] = []
    except Exception as e:
        print(f"âŒ ä¸Šè¯ç‚¹ä½å¤±è´¥: {e}")
        export_data['sh_index'] = []

    # ä¹å’• PE/PB
    try:
        df_pe = ak.stock_market_pe_lg(symbol="ä¸Šè¯")
        if 'æ—¥æœŸ' in df_pe.columns and 'å¹³å‡å¸‚ç›ˆç‡' in df_pe.columns:
            df_pe['date'] = pd.to_datetime(df_pe['æ—¥æœŸ'])
            df_pe['value'] = df_pe['å¹³å‡å¸‚ç›ˆç‡'].apply(clean_value)
            try: df_m = df_pe.resample('ME', on='date').last().reset_index()
            except: df_m = df_pe.set_index('date').resample('M').last().reset_index()
            df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d')
            export_data['sh_index_pe'] = df_m[['date','value']].to_dict('records')
            print(f"âœ… ä¸Šè¯PE (Legu): {len(df_m)} æ¡")
        else: raise Exception("PEåˆ—åé”™")
    except: export_data['sh_index_pe'] = []

    try:
        df_pb = ak.stock_market_pb_lg(symbol="ä¸Šè¯")
        if 'æ—¥æœŸ' in df_pb.columns and 'å¸‚å‡€ç‡' in df_pb.columns:
            df_pb['date'] = pd.to_datetime(df_pb['æ—¥æœŸ'])
            df_pb['value'] = df_pb['å¸‚å‡€ç‡'].apply(clean_value)
            try: df_m = df_pb.resample('ME', on='date').last().reset_index()
            except: df_m = df_pb.set_index('date').resample('M').last().reset_index()
            df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d')
            export_data['sh_index_pb'] = df_m[['date','value']].to_dict('records')
            print(f"âœ… ä¸Šè¯PB (Legu): {len(df_m)} æ¡")
        else: raise Exception("PBåˆ—åé”™")
    except: export_data['sh_index_pb'] = []

    # å€ºå¸‚
    try:
        df = ak.bond_zh_us_rate()
        col_d = find_column(df.columns, ['æ—¥æœŸ'])
        col_us = find_column(df.columns, ['ç¾å›½', '10å¹´'])
        col_cn = find_column(df.columns, ['ä¸­å›½', '10å¹´'])
        if col_d and col_us and col_cn:
            df['date'] = pd.to_datetime(df[col_d])
            df['us'] = df[col_us].apply(clean_value)
            df['cn'] = df[col_cn].apply(clean_value)
            df['spread'] = df['cn'] - df['us']
            df = df.dropna(subset=['us','cn','date']).sort_values('date')
            try: df_m = df.resample('ME', on='date').last().reset_index()
            except: df_m = df.set_index('date').resample('M').last().reset_index()
            df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d')
            export_data['us_bond_10y'] = df_m[['date','us']].rename(columns={'us':'value'}).to_dict('records')
            export_data['cn_bond_10y'] = df_m[['date','cn']].rename(columns={'cn':'value'}).to_dict('records')
            export_data['bond_spread'] = df_m[['date','spread']].rename(columns={'spread':'value'}).to_dict('records')
            print(f"âœ… å€ºå¸‚: {len(df_m)} æ¡")
        else: raise Exception("å€ºå¸‚åˆ—åé”™")
    except Exception as e:
        print(f"âŒ å€ºå¸‚å¤±è´¥: {e}")
        export_data['us_bond_10y'], export_data['cn_bond_10y'], export_data['bond_spread'] = [], [], []

    # æ±‡ç‡
    try:
        df = ak.currency_boc_safe()
        col_d = find_possible_columns(df.columns, [['æ—¥æœŸ'], ['å‘å¸ƒæ—¥æœŸ']])
        col_usd = find_column(df.columns, ['ç¾å…ƒ'])
        if col_d and col_usd:
            df['date'] = pd.to_datetime(df[col_d])
            df['value'] = df[col_usd].apply(clean_value)
            df = df.dropna(subset=['value']).sort_values('date')
            try: df_m = df.resample('ME', on='date').last().reset_index()
            except: df_m = df.set_index('date').resample('M').last().reset_index()
            df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d')
            export_data['usd_cny'] = df_m[['date','value']].to_dict('records')
            print(f"âœ… æ±‡ç‡: {len(df_m)} æ¡")
        else: raise Exception("æ±‡ç‡åˆ—åé”™")
    except: export_data['usd_cny'] = []

    # å¤–å‚¨
    try:
        df = ak.macro_china_fx_gold()
        col_d = find_column(df.columns, ['æœˆä»½'])
        col_v = find_possible_columns(df.columns, [['å›½å®¶å¤–æ±‡å‚¨å¤‡', 'æ•°å€¼'], ['å¤–æ±‡å‚¨å¤‡', 'æ•°å€¼']])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['fx_reserves'] = res
            print(f"âœ… å¤–å‚¨: {len(res)} æ¡")
        else: raise Exception("å¤–å‚¨åˆ—åé”™")
    except: export_data['fx_reserves'] = []

    # é»„é‡‘
    try:
        df = ak.spot_hist_sge(symbol="Au99.99")
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'])
            try: df_m = df.resample('ME', on='date').last().reset_index()
            except: df_m = df.set_index('date').resample('M').last().reset_index()
            df_m['date'] = df_m['date'].dt.strftime('%Y-%m-%d')
            df_m['value'] = df_m['close']
            res = df_m[['date','value']].to_dict('records')
            export_data['gold'] = res
            print(f"âœ… é»„é‡‘: {len(res)} æ¡")
        else: raise Exception("é»„é‡‘åˆ—åé”™")
    except: export_data['gold'] = []

    # 6. ç»“æ„
    print("\n>>> [6. ç»“æ„ç»„]")
    try:
        df = ak.macro_cnbs()
        if 'å¹´ä»½' in df.columns and 'å±…æ°‘éƒ¨é—¨' in df.columns:
            df['date'] = df['å¹´ä»½'].apply(smart_date_parser)
            df['value'] = df['å±…æ°‘éƒ¨é—¨'].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['resident_leverage'] = res
            print(f"âœ… å±…æ°‘æ æ†: {len(res)} æ¡")
        else: raise Exception("å±…æ°‘æ æ†åˆ—åé”™")
    except: export_data['resident_leverage'] = []

    try:
        df = ak.macro_china_real_estate()
        col_d = find_column(df.columns, ['æ—¥æœŸ'])
        col_v = find_column(df.columns, ['æœ€æ–°å€¼']) or find_column(df.columns, ['æŒ‡æ•°'])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['real_estate_invest'] = res
            print(f"âœ… å›½æˆ¿æ™¯æ°”: {len(res)} æ¡")
        else: raise Exception("å›½æˆ¿æ™¯æ°”åˆ—åé”™")
    except: export_data['real_estate_invest'] = []

    try:
        df = ak.macro_china_urban_unemployment()
        df.columns = df.columns.str.strip()
        col_d = find_possible_columns(df.columns, [['date'], ['æ—¥æœŸ']])
        col_v = find_possible_columns(df.columns, [['value'], ['å¤±ä¸šç‡']])
        if col_d and col_v:
            df['date'] = df[col_d].apply(smart_date_parser)
            df['value'] = df[col_v].apply(clean_value)
            if 'item' in df.columns:
                df = df[df['item'].str.contains('å…¨å›½', na=False)]
            res = df.dropna(subset=['value','date']).sort_values('date')[['date','value']].to_dict('records')
            export_data['unemployment'] = res
            print(f"âœ… å¤±ä¸šç‡: {len(res)} æ¡")
        else: raise Exception("å¤±ä¸šç‡åˆ—åé”™")
    except: export_data['unemployment'] = []

    # Meta
    export_data["meta"] = {
        "source": "AkShare v23",
        "updated_at": pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    return export_data

# ==========================================
# 3. æ ¡éªŒä¸ç”Ÿæˆ
# ==========================================
def validate_and_generate(data, filename="macro_data.ts"):
    print("\n" + "="*60)
    print("ğŸš¦ ç†”æ–­æ ¡éªŒ...")
    missing_data = []
    
    for key in CRITICAL_KEYS:
        if key not in data or not data[key]:
            missing_data.append(key)
    
    if len(missing_data) > 0:
        print("â›”ï¸ ç†”æ–­è§¦å‘ï¼ç¼ºå¤±æŒ‡æ ‡ï¼š")
        for k in missing_data: print(f"   âŒ {k}")
        sys.exit(1)
    
    print("âœ… æ ¡éªŒé€šè¿‡ï¼æ­£åœ¨ç”Ÿæˆç˜¦èº«ç‰ˆæ–‡ä»¶...")
    script_dir = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(script_dir, filename)
    
    # æ„é€ æœ€ç»ˆè¾“å‡ºå¯¹è±¡ï¼š labels + data
    final_output = {
        "labels": INDICATOR_MAP,
        "data": data,
        "meta": data.pop("meta") # ç§»åŠ¨ meta
    }
    
    json_str = json.dumps(final_output, indent=2, ensure_ascii=False)
    
    # TS ç»“æ„å®šä¹‰ä¹Ÿéšä¹‹æ›´æ–°
    ts_content = f"""// Auto-generated (v23.0 Optimized)
// Updated at: {final_output['meta']['updated_at']}

export interface MacroDataPoint {{
  date: string;
  value: number;
}}

export interface MacroDataResponse {{
  labels: {{ [key: string]: string }};
  data: {{
    // ä»·æ ¼
    cpi: MacroDataPoint[];
    ppi: MacroDataPoint[];
    // è´§å¸
    m1: MacroDataPoint[];
    m2: MacroDataPoint[];
    scissors: MacroDataPoint[];
    social_financing: MacroDataPoint[];
    lpr_1y: MacroDataPoint[];
    lpr_5y: MacroDataPoint[];
    // å¢é•¿
    gdp: MacroDataPoint[];
    pmi: MacroDataPoint[];
    exports_yoy: MacroDataPoint[];
    // æ¶ˆè´¹
    retail_sales: MacroDataPoint[];
    // å¸‚åœº
    sh_index: MacroDataPoint[];
    sh_index_pe: MacroDataPoint[];
    sh_index_pb: MacroDataPoint[];
    us_bond_10y: MacroDataPoint[];
    cn_bond_10y: MacroDataPoint[];
    bond_spread: MacroDataPoint[];
    usd_cny: MacroDataPoint[];
    fx_reserves: MacroDataPoint[];
    gold: MacroDataPoint[];
    // ç»“æ„
    resident_leverage: MacroDataPoint[];
    real_estate_invest: MacroDataPoint[];
    unemployment: MacroDataPoint[];
  }};
  meta: {{
    source: string;
    updated_at: string;
  }};
}}

export const MACRO_DATA: MacroDataResponse = {json_str};
"""
    with open(file_path, "w", encoding="utf-8") as f:
        f.write(ts_content)
    print(f"âœ¨ æˆåŠŸ! æ–‡ä»¶å·²ç”Ÿæˆ: {file_path}")

if __name__ == "__main__":
    sys.setrecursionlimit(5000)
    data = fetch_macro_data_v23()
    validate_and_generate(data)