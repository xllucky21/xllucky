import akshare as ak
import yfinance as yf
import pandas as pd
import json
import os
import sys
import time
import argparse
from datetime import datetime, timedelta

import requests
import urllib3
import ssl
import warnings

# ==========================================
# ğŸ›¡ï¸ ç³»ç»Ÿåº•å±‚é…ç½®
# ==========================================
warnings.filterwarnings("ignore")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å…¨å±€ SSL ç¦ç”¨
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Requests ä¼ªè£…
old_session_request = requests.Session.request
def new_session_request(self, method, url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    return old_session_request(self, method, url, *args, **kwargs)
requests.Session.request = new_session_request

old_get = requests.get
old_post = requests.post
def new_get(url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].setdefault('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    return old_get(url, *args, **kwargs)
def new_post(url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].setdefault('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    return old_post(url, *args, **kwargs)
requests.get = new_get
requests.post = new_post

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
OUTPUT_FILENAME = "us_market_data.ts"
LIMIT_DAYS = 2000  # è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ® (çº¦8å¹´)

CURRENT_DIR = sys.path[0]
OUTPUT_PATH = os.path.join(CURRENT_DIR, OUTPUT_FILENAME)

# æ˜æ˜Ÿè‚¡ç¥¨ä»£ç  (ä¸œè´¢æ ¼å¼)
STAR_STOCKS = {
    "AAPL": "105.AAPL",   # è‹¹æœ
    "MSFT": "105.MSFT",   # å¾®è½¯
    "NVDA": "105.NVDA",   # è‹±ä¼Ÿè¾¾
    "GOOGL": "105.GOOGL", # è°·æ­Œ
    "AMZN": "105.AMZN",   # äºšé©¬é€Š
    "META": "105.META",   # Meta
    "TSLA": "105.TSLA",   # ç‰¹æ–¯æ‹‰
}

# æ¿å—ETF (ä½¿ç”¨yfinanceè·å–)
SECTOR_ETFS = {
    "XLK": "XLK",   # ç§‘æŠ€
    "XLF": "XLF",   # é‡‘è
    "XLE": "XLE",   # èƒ½æº
    "XLV": "XLV",   # åŒ»ç–—å¥åº·
    "XLI": "XLI",   # å·¥ä¸š
    "XLY": "XLY",   # å¯é€‰æ¶ˆè´¹
}

# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================

def safe_fetch(func, name, **kwargs):
    """é€šç”¨å®‰å…¨æŠ“å–å‡½æ•°"""
    print(f"â³ [{name}] æ­£åœ¨è·å–...", end="", flush=True)
    try:
        start = time.time()
        df = func(**kwargs)
        
        if df is None or df.empty:
            print(f"\râš ï¸ [{name}] è·å–ç»“æœä¸ºç©º")
            return []
            
        elapsed = time.time() - start
        print(f"\râœ… [{name}] æˆåŠŸ! ({len(df)} æ¡, {elapsed:.2f}s)")
        return df.to_dict(orient='records')
    except Exception as e:
        print(f"\râŒ [{name}] å¤±è´¥: {str(e)}")
        return []

# ================= ğŸ“Š æ•°æ®è·å–é€»è¾‘ =================

def get_us_index(symbol):
    """è·å–ç¾è‚¡æŒ‡æ•° (é“ç¼æ–¯/æ ‡æ™®500/çº³æ–¯è¾¾å…‹)"""
    # ä½¿ç”¨ä¸œè´¢æ¥å£è·å–ç¾è‚¡æŒ‡æ•°
    df = ak.index_us_stock_sina(symbol=symbol)
    
    df = df.reset_index()
    if 'date' not in df.columns:
        df.rename(columns={'index': 'date'}, inplace=True)
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
    result['close'] = pd.to_numeric(df['close'], errors='coerce')
    result['open'] = pd.to_numeric(df['open'], errors='coerce')
    result['high'] = pd.to_numeric(df['high'], errors='coerce')
    result['low'] = pd.to_numeric(df['low'], errors='coerce')
    
    if 'volume' in df.columns:
        result['volume'] = pd.to_numeric(df['volume'], errors='coerce')
    else:
        result['volume'] = 0
    
    result = result.dropna(subset=['close'])
    result = result.sort_values('date')
    
    if LIMIT_DAYS:
        result = result.tail(LIMIT_DAYS)
    return result

def get_us_stock(symbol_code):
    """è·å–ç¾è‚¡ä¸ªè‚¡æ•°æ®"""
    df = ak.stock_us_hist(symbol=symbol_code, start_date="20150101", end_date="20501231", adjust="qfq")
    
    if df is None or df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    result['close'] = pd.to_numeric(df['æ”¶ç›˜'], errors='coerce')
    result['open'] = pd.to_numeric(df['å¼€ç›˜'], errors='coerce')
    result['high'] = pd.to_numeric(df['æœ€é«˜'], errors='coerce')
    result['low'] = pd.to_numeric(df['æœ€ä½'], errors='coerce')
    result['volume'] = pd.to_numeric(df['æˆäº¤é‡'], errors='coerce')
    result['change_pct'] = pd.to_numeric(df['æ¶¨è·Œå¹…'], errors='coerce')
    
    result = result.dropna(subset=['close'])
    result = result.sort_values('date')
    
    if LIMIT_DAYS:
        result = result.tail(LIMIT_DAYS)
    return result

def get_etf_yf(symbol):
    """ä½¿ç”¨yfinanceè·å–ETFæ•°æ®"""
    try:
        ticker = yf.Ticker(symbol)
        df = ticker.history(period="max")
        
        if df.empty:
            return pd.DataFrame()
        
        df = df.reset_index()
        result = pd.DataFrame()
        result['date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        result['close'] = pd.to_numeric(df['Close'], errors='coerce')
        result['open'] = pd.to_numeric(df['Open'], errors='coerce')
        result['high'] = pd.to_numeric(df['High'], errors='coerce')
        result['low'] = pd.to_numeric(df['Low'], errors='coerce')
        result['volume'] = pd.to_numeric(df['Volume'], errors='coerce')
        
        result = result.dropna(subset=['close'])
        result = result.sort_values('date')
        
        if LIMIT_DAYS:
            result = result.tail(LIMIT_DAYS)
        return result
    except Exception as e:
        print(f"ETF {symbol} è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def get_vix():
    """è·å–VIXææ…ŒæŒ‡æ•° (ä½¿ç”¨yfinance)"""
    try:
        ticker = yf.Ticker("^VIX")
        df = ticker.history(period="max")
        
        if df.empty:
            return pd.DataFrame()
        
        df = df.reset_index()
        result = pd.DataFrame()
        result['date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        result['close'] = pd.to_numeric(df['Close'], errors='coerce')
        result['open'] = pd.to_numeric(df['Open'], errors='coerce')
        result['high'] = pd.to_numeric(df['High'], errors='coerce')
        result['low'] = pd.to_numeric(df['Low'], errors='coerce')
        
        result = result.dropna(subset=['close'])
        result = result.sort_values('date')
        
        if LIMIT_DAYS:
            result = result.tail(LIMIT_DAYS)
        return result
    except Exception as e:
        print(f"VIXè·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def get_us_bond_yield():
    """è·å–ç¾å›½å›½å€ºæ”¶ç›Šç‡ (2å¹´/10å¹´)"""
    df = ak.bond_zh_us_rate()
    
    if df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    result['us_2y'] = pd.to_numeric(df['ç¾å›½å›½å€ºæ”¶ç›Šç‡2å¹´'], errors='coerce')
    result['us_10y'] = pd.to_numeric(df['ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´'], errors='coerce')
    # 2-10å¹´åˆ©å·® (æ”¶ç›Šç‡æ›²çº¿)
    result['spread_2_10'] = round(result['us_10y'] - result['us_2y'], 4)
    
    result = result.dropna(subset=['us_10y'])
    result = result.sort_values('date')
    
    if LIMIT_DAYS:
        result = result.tail(LIMIT_DAYS)
    return result

def get_dollar_index():
    """è·å–ç¾å…ƒæŒ‡æ•° DXY (ä½¿ç”¨yfinance)"""
    try:
        ticker = yf.Ticker("DX-Y.NYB")  # ç¾å…ƒæŒ‡æ•°æœŸè´§
        df = ticker.history(period="max")
        
        if df.empty:
            return pd.DataFrame()
        
        df = df.reset_index()
        result = pd.DataFrame()
        result['date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')
        result['close'] = pd.to_numeric(df['Close'], errors='coerce')
        
        result = result.dropna(subset=['close'])
        result = result.sort_values('date')
        
        if LIMIT_DAYS:
            result = result.tail(LIMIT_DAYS)
        return result
    except Exception as e:
        print(f"ç¾å…ƒæŒ‡æ•°è·å–å¤±è´¥: {e}")
        return pd.DataFrame()

def get_fed_funds_rate():
    """è·å–è”é‚¦åŸºé‡‘åˆ©ç‡"""
    # è¯¥æ¥å£å·²ä¸å¯ç”¨ï¼Œè¿”å›ç©ºæ•°æ®
    return pd.DataFrame()

# ================= ğŸ’¾ ç”Ÿæˆé€»è¾‘ =================

def load_existing_data():
    """åŠ è½½ç°æœ‰æ•°æ®æ–‡ä»¶"""
    if not os.path.exists(OUTPUT_PATH):
        return None
    try:
        with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:
            content = f.read()
            start = content.find('{')
            end = content.rfind('}') + 1
            if start == -1 or end == 0:
                return None
            json_str = content[start:end]
            return json.loads(json_str)
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return None

def merge_data(existing_list, new_list, date_key='date'):
    """åˆå¹¶æ•°æ®ï¼Œå»é‡å¹¶æŒ‰æ—¥æœŸæ’åº"""
    if not existing_list:
        return new_list
    if not new_list:
        return existing_list
    
    merged = {d[date_key]: d for d in existing_list}
    for d in new_list:
        merged[d[date_key]] = d
    
    result = sorted(merged.values(), key=lambda x: x[date_key])
    
    if LIMIT_DAYS and len(result) > LIMIT_DAYS:
        result = result[-LIMIT_DAYS:]
    
    return result

def generate_ts_file(data_map):
    print("\nğŸ’¾ æ­£åœ¨ç”Ÿæˆ TypeScript æ–‡ä»¶...")
    
    final_obj = {
        "meta": {
            "updated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "desc": "ç¾è‚¡å¸‚åœºç»¼åˆæ•°æ® - ä¸‰å¤§æŒ‡æ•°/VIX/å›½å€º/ç¾å…ƒ/æ¿å—/æ˜æ˜Ÿè‚¡"
        },
        "data": data_map
    }
    
    json_str = json.dumps(final_obj, ensure_ascii=False, indent=2)
    
    ts_content = f"""/**
 * ç¾è‚¡å…¨ç»´åˆ†ææ•°æ®
 * è‡ªåŠ¨ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
 */

export const US_MARKET = {json_str};
"""
    try:
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            f.write(ts_content)
        print(f"ğŸ‰ æˆåŠŸ! æ–‡ä»¶å·²ç”Ÿæˆåœ¨: {OUTPUT_PATH}")
    except Exception as e:
        print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")

def fetch_full_data():
    """å…¨é‡è·å–æ‰€æœ‰æ•°æ®"""
    print("ğŸš€ å¼€å§‹è·å–ç¾è‚¡å¸‚åœºæ•°æ® (å…¨é‡æ¨¡å¼)...")
    print("-" * 40)
    
    # 1. ä¸‰å¤§æŒ‡æ•°
    dji = safe_fetch(get_us_index, "é“ç¼æ–¯å·¥ä¸š", symbol=".DJI")
    spx = safe_fetch(get_us_index, "æ ‡æ™®500", symbol=".INX")
    ndx = safe_fetch(get_us_index, "çº³æ–¯è¾¾å…‹", symbol=".IXIC")
    
    # 2. VIXææ…ŒæŒ‡æ•°
    vix = safe_fetch(get_vix, "VIXææ…ŒæŒ‡æ•°")
    
    # 3. ç¾å€ºæ”¶ç›Šç‡
    bond = safe_fetch(get_us_bond_yield, "ç¾å›½å›½å€ºæ”¶ç›Šç‡")
    
    # 4. ç¾å…ƒæŒ‡æ•°
    dollar = safe_fetch(get_dollar_index, "ç¾å…ƒæŒ‡æ•°")
    
    # 5. è”é‚¦åŸºé‡‘åˆ©ç‡
    fed_rate = safe_fetch(get_fed_funds_rate, "è”é‚¦åŸºé‡‘åˆ©ç‡")
    
    # 6. æ¿å—ETF (ä½¿ç”¨yfinance)
    sectors = {}
    for etf_name, symbol in SECTOR_ETFS.items():
        sectors[etf_name.lower()] = safe_fetch(get_etf_yf, f"æ¿å—ETF-{etf_name}", symbol=symbol)
        time.sleep(0.3)  # é¿å…è¯·æ±‚è¿‡å¿«
    
    # 7. æ˜æ˜Ÿè‚¡ç¥¨
    stars = {}
    for stock_name, code in STAR_STOCKS.items():
        stars[stock_name.lower()] = safe_fetch(get_us_stock, f"æ˜æ˜Ÿè‚¡-{stock_name}", symbol_code=code)
        time.sleep(0.3)
    
    print("-" * 40)
    
    # æ£€æŸ¥æ ¸å¿ƒæ•°æ®
    if not dji and not spx and not ndx:
        print("ğŸ›‘ ä¸¥é‡é”™è¯¯ï¼šä¸‰å¤§æŒ‡æ•°æ•°æ®å…¨éƒ¨è·å–å¤±è´¥ï¼Œå–æ¶ˆç”Ÿæˆæ–‡ä»¶ã€‚")
        sys.exit(1)
        
    return {
        "indices": {
            "dji": dji,      # é“ç¼æ–¯
            "spx": spx,      # æ ‡æ™®500
            "ndx": ndx,      # çº³æ–¯è¾¾å…‹
        },
        "vix": vix,
        "bond": bond,
        "dollar": dollar,
        "fed_rate": fed_rate,
        "sectors": sectors,
        "stars": stars,
    }

def fetch_incremental_data(days=30):
    """å¢é‡è·å–æœ€è¿‘Nå¤©æ•°æ®"""
    print(f"ğŸš€ å¼€å§‹è·å–ç¾è‚¡å¸‚åœºæ•°æ® (å¢é‡æ¨¡å¼: æœ€è¿‘{days}å¤©)...")
    print("-" * 40)
    
    existing = load_existing_data()
    if not existing:
        print("âš ï¸ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®ï¼Œåˆ‡æ¢åˆ°å…¨é‡æ¨¡å¼...")
        return fetch_full_data()
    
    existing_data = existing.get('data', {})
    last_update = existing.get('meta', {}).get('updated_at', 'æœªçŸ¥')
    print(f"ğŸ“‚ å·²åŠ è½½ç°æœ‰æ•°æ® (ä¸Šæ¬¡æ›´æ–°: {last_update})")
    
    global LIMIT_DAYS
    original_limit = LIMIT_DAYS
    LIMIT_DAYS = days
    
    try:
        # è·å–æ–°æ•°æ®
        dji_new = safe_fetch(get_us_index, "é“ç¼æ–¯å·¥ä¸š", symbol=".DJI")
        spx_new = safe_fetch(get_us_index, "æ ‡æ™®500", symbol=".INX")
        ndx_new = safe_fetch(get_us_index, "çº³æ–¯è¾¾å…‹", symbol=".IXIC")
        vix_new = safe_fetch(get_vix, "VIXææ…ŒæŒ‡æ•°")
        bond_new = safe_fetch(get_us_bond_yield, "ç¾å›½å›½å€ºæ”¶ç›Šç‡")
        dollar_new = safe_fetch(get_dollar_index, "ç¾å…ƒæŒ‡æ•°")
        fed_rate_new = safe_fetch(get_fed_funds_rate, "è”é‚¦åŸºé‡‘åˆ©ç‡")
        
        sectors_new = {}
        for etf_name, symbol in SECTOR_ETFS.items():
            sectors_new[etf_name.lower()] = safe_fetch(get_etf_yf, f"æ¿å—ETF-{etf_name}", symbol=symbol)
            time.sleep(0.3)
        
        stars_new = {}
        for stock_name, code in STAR_STOCKS.items():
            stars_new[stock_name.lower()] = safe_fetch(get_us_stock, f"æ˜æ˜Ÿè‚¡-{stock_name}", symbol_code=code)
            time.sleep(0.3)
            
    finally:
        LIMIT_DAYS = original_limit
    
    print("-" * 40)
    print("ğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
    
    # åˆå¹¶æŒ‡æ•°æ•°æ®
    existing_indices = existing_data.get('indices', {})
    merged_indices = {
        "dji": merge_data(existing_indices.get('dji', []), dji_new),
        "spx": merge_data(existing_indices.get('spx', []), spx_new),
        "ndx": merge_data(existing_indices.get('ndx', []), ndx_new),
    }
    
    # åˆå¹¶æ¿å—æ•°æ®
    existing_sectors = existing_data.get('sectors', {})
    merged_sectors = {}
    for name in SECTOR_ETFS.keys():
        key = name.lower()
        merged_sectors[key] = merge_data(existing_sectors.get(key, []), sectors_new.get(key, []))
    
    # åˆå¹¶æ˜æ˜Ÿè‚¡æ•°æ®
    existing_stars = existing_data.get('stars', {})
    merged_stars = {}
    for name in STAR_STOCKS.keys():
        key = name.lower()
        merged_stars[key] = merge_data(existing_stars.get(key, []), stars_new.get(key, []))
    
    return {
        "indices": merged_indices,
        "vix": merge_data(existing_data.get('vix', []), vix_new),
        "bond": merge_data(existing_data.get('bond', []), bond_new),
        "dollar": merge_data(existing_data.get('dollar', []), dollar_new),
        "fed_rate": merge_data(existing_data.get('fed_rate', []), fed_rate_new),
        "sectors": merged_sectors,
        "stars": merged_stars,
    }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='ç¾è‚¡æ•°æ®è·å–å·¥å…·')
    parser.add_argument('--mode', choices=['full', 'incremental'], default='incremental',
                        help='è·å–æ¨¡å¼: full=å…¨é‡, incremental=å¢é‡ (é»˜è®¤: incremental)')
    parser.add_argument('--days', type=int, default=30,
                        help='å¢é‡æ¨¡å¼ä¸‹è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ® (é»˜è®¤: 30)')
    args = parser.parse_args()
    
    if args.mode == 'full':
        data_map = fetch_full_data()
    else:
        data_map = fetch_incremental_data(days=args.days)
    
    generate_ts_file(data_map)
