import akshare as ak
import pandas as pd
import json
import os
import sys
import time
import argparse
from datetime import datetime, timedelta

import requests
import urllib3
import ssl
import warnings
# ==========================================
# ğŸ›¡ï¸ ç³»ç»Ÿåº•å±‚é…ç½®
# ==========================================
warnings.filterwarnings("ignore")
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# å…¨å±€ SSL ç¦ç”¨
try:
    _create_unverified_https_context = ssl._create_unverified_context
except AttributeError:
    pass
else:
    ssl._create_default_https_context = _create_unverified_https_context

# Requests ä¼ªè£… - åŒæ—¶ patch Session.request å’Œå…¨å±€ request/get/post
old_session_request = requests.Session.request
def new_session_request(self, method, url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].update({
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
    })
    return old_session_request(self, method, url, *args, **kwargs)
requests.Session.request = new_session_request

# Patch requests.get/post ç­‰å…¨å±€æ–¹æ³• (akshare éƒ¨åˆ†æ¥å£ç›´æ¥è°ƒç”¨è¿™äº›)
old_get = requests.get
old_post = requests.post
def new_get(url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].setdefault('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    return old_get(url, *args, **kwargs)
def new_post(url, *args, **kwargs):
    kwargs['verify'] = False
    if 'headers' not in kwargs:
        kwargs['headers'] = {}
    kwargs['headers'].setdefault('User-Agent', 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36')
    return old_post(url, *args, **kwargs)
requests.get = new_get
requests.post = new_post

# ================= âš™ï¸ é…ç½®åŒºåŸŸ =================
OUTPUT_FILENAME = "market_data_full.ts"
LIMIT_DAYS = 3000  # è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ® (çº¦8å¹´)

# ç¡®ä¿æ–‡ä»¶ç”Ÿæˆåœ¨è„šæœ¬æ‰€åœ¨çš„åŒçº§ç›®å½•
CURRENT_DIR = sys.path[0]
OUTPUT_PATH = os.path.join(CURRENT_DIR, OUTPUT_FILENAME)

# ================= ğŸ› ï¸ å·¥å…·å‡½æ•° =================

def safe_fetch(func, name, **kwargs):
    """é€šç”¨å®‰å…¨æŠ“å–å‡½æ•°ï¼Œå¸¦é‡è¯•å’Œé”™è¯¯æ•è·"""
    print(f"â³ [{name}] æ­£åœ¨è·å–...", end="", flush=True)
    try:
        start = time.time()
        # æ‰§è¡Œä¼ å…¥çš„å‡½æ•°
        df = func(**kwargs)
        
        if df is None or df.empty:
            print(f"\râš ï¸ [{name}] è·å–ç»“æœä¸ºç©º (å¯èƒ½æ˜¯æ¥å£æ— æ•°æ®)")
            return []
            
        elapsed = time.time() - start
        print(f"\râœ… [{name}] æˆåŠŸ! ({len(df)} æ¡, {elapsed:.2f}s)")
        return df.to_dict(orient='records')
    except Exception as e:
        print(f"\râŒ [{name}] å¤±è´¥: {str(e)}")
        return []

# ================= ğŸ“Š æ•°æ®è·å–é€»è¾‘ =================

def get_a_share():
    """Aè‚¡ä¸¤å¸‚æˆäº¤é¢ (ä¸œæ–¹è´¢å¯Œæº)"""
    # ä¸Šè¯æŒ‡æ•°
    sh = ak.stock_zh_index_daily_em(symbol="sh000001")
    # æ·±è¯æˆæŒ‡
    sz = ak.stock_zh_index_daily_em(symbol="sz399001")
    
    # æå–éœ€è¦çš„åˆ—
    sh = sh[['date', 'amount', 'close']].rename(columns={'amount': 'sh_amt', 'close': 'sh_close'})
    sz = sz[['date', 'amount', 'close']].rename(columns={'amount': 'sz_amt', 'close': 'sz_close'})
    
    # åˆå¹¶
    df = pd.merge(sh, sz, on='date', how='inner')
    
    # è®¡ç®—æ€»æˆäº¤é¢ (äº¿å…ƒ)
    df['total_amount_yi'] = round((df['sh_amt'] + df['sz_amt']) / 100000000, 2)
    df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
    df = df.sort_values('date')
    
    if LIMIT_DAYS: df = df.tail(LIMIT_DAYS)
    return df[['date', 'total_amount_yi', 'sh_close', 'sz_close']]

def get_hk_index_data(symbol_em, symbol_sina, name_arg):
    """
    æ¸¯è‚¡æŒ‡æ•°è·å– (ä¼˜å…ˆå°è¯•ä¸œè´¢EMæºï¼Œå¤±è´¥å°è¯•æ–°æµªSinaæº)
    symbol_em: ä¸œè´¢ä»£ç  (å¦‚ 'HSI')
    symbol_sina: æ–°æµªä»£ç  (å¦‚ 'HSI')
    """
    # 1. å°è¯•ä¸œè´¢æº (é€šå¸¸åŒ…å«æˆäº¤é¢)
    # è¿™é‡Œçš„ symbol å®é™…ä¸Š akshare å†…éƒ¨ä¼šè‡ªåŠ¨å¤„ç†å‰ç¼€ï¼Œé€šå¸¸ä¼  'HSI' å³å¯
    # å¯¹åº”çš„æ¥å£æ–‡æ¡£: stock_hk_index_daily_em
    try:
        df = ak.stock_hk_index_daily_em(symbol=symbol_em)
        # ä¸œè´¢è¿”å›åˆ—: date, open, close, high, low, volume, amount
        if 'amount' in df.columns:
             # æ¸¯è‚¡ amount å•ä½é€šå¸¸æ˜¯å…ƒï¼Œè½¬ä¸ºäº¿å…ƒ
            df['amount_yi'] = round(df['amount'] / 100000000, 2)
        else:
            df['amount_yi'] = 0 # å¦‚æœæ²¡æˆäº¤é¢ï¼Œè®¾ä¸º0
            
        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
        df = df.sort_values('date')
        if LIMIT_DAYS: df = df.tail(LIMIT_DAYS)
        return df[['date', 'amount_yi', 'close']]
        
    except Exception:
        # print(f"\râš ï¸ [{name_arg}] ä¸œè´¢æºå¤±è´¥ï¼Œå°è¯•æ–°æµªæº...", end="")
        pass

    # 2. å›é€€åˆ°æ–°æµªæº (stock_hk_index_daily_sina)
    try:
        df = ak.stock_hk_index_daily_sina(symbol=symbol_sina)
        df = df.reset_index()
        if 'date' not in df.columns: df.rename(columns={'index': 'date'}, inplace=True)
        
        # æ–°æµªæºç»å¸¸åªæœ‰ volume (æˆäº¤é‡è‚¡æ•°) æ²¡æœ‰ amount (æˆäº¤é¢èµ„é‡‘)
        # å¦‚æœæœ‰ amount åˆ™ä½¿ç”¨ï¼Œæ²¡æœ‰åˆ™ç½® 0
        if 'amount' in df.columns:
            df['amount_yi'] = round(df['amount'] / 100000000, 2)
        else:
            df['amount_yi'] = 0 
            
        df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
        df = df.sort_values('date')
        if LIMIT_DAYS: df = df.tail(LIMIT_DAYS)
        return df[['date', 'amount_yi', 'close']]
    except Exception as e:
        raise e # æŠ›å‡ºå¼‚å¸¸ç»™ safe_fetch å¤„ç†

def get_hsgt_funds(symbol):
    """æ²ªæ·±æ¸¯é€šèµ„é‡‘ (åŒ—å‘/å—å‘)
    
    æ³¨æ„: 2024å¹´8æœˆ19æ—¥èµ·ï¼ŒåŒ—å‘èµ„é‡‘ä¸å†æŠ«éœ²æ¯æ—¥æµå…¥æµå‡ºæ•°æ®ï¼Œæ”¹ä¸ºæŒ‰å­£åº¦å‘å¸ƒ
    å› æ­¤ 2024-08-19 ä¹‹åçš„åŒ—å‘èµ„é‡‘æ•°æ®å°†ä¸ºç©º
    """
    df = ak.stock_hsgt_hist_em(symbol=symbol)
    
    # ç›´æ¥ä½¿ç”¨åŸå§‹åˆ—åï¼Œæ›´ç²¾ç¡®
    # akshare è¿”å›çš„åˆ—: æ—¥æœŸ, å½“æ—¥æˆäº¤å‡€ä¹°é¢, ä¹°å…¥æˆäº¤é¢, å–å‡ºæˆäº¤é¢, ...
    if 'æ—¥æœŸ' not in df.columns or 'å½“æ—¥æˆäº¤å‡€ä¹°é¢' not in df.columns:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    result['net_inflow_yi'] = pd.to_numeric(df['å½“æ—¥æˆäº¤å‡€ä¹°é¢'], errors='coerce')
    
    # è¿‡æ»¤æ‰ NaN æ•°æ® (2024-08-19 èµ·åŒ—å‘èµ„é‡‘åœæ­¢æ¯æ—¥æŠ«éœ²)
    result = result.dropna(subset=['net_inflow_yi'])
    result = result.sort_values('date')
    
    if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
    return result[['date', 'net_inflow_yi']]

def get_exchange_rate():
    """æ±‡ç‡: ä½¿ç”¨ä¸œæ–¹è´¢å¯Œå¤–æ±‡å†å²æ•°æ®"""
    try:
        # ä½¿ç”¨ forex_hist_em è·å–ç¾å…ƒå…‘ç¦»å²¸äººæ°‘å¸å†å²
        df = ak.forex_hist_em(symbol='USDCNH')
        
        if df.empty: 
            raise Exception("forex_hist_em è¿”å›ç©º")
        
        result = pd.DataFrame()
        result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
        result['rate'] = pd.to_numeric(df['æœ€æ–°ä»·'], errors='coerce')
        result = result.dropna()
        result = result.sort_values('date')
        
        if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
        return result[['date', 'rate']]
        
    except Exception as e:
        print(f"forex_hist_em error: {e}")
        return pd.DataFrame()

def get_nasdaq_etf():
    """ç¾è‚¡: ä½¿ç”¨ QQQ (çº³æŒ‡100 ETF) ä»£æ›¿æŒ‡æ•°ï¼Œæ¥å£æ›´ç¨³"""
    # stock_us_hist æ¥å£ï¼Œsymbol="105.QQQ" (ä¸œè´¢ä»£ç )
    df = ak.stock_us_hist(symbol="105.QQQ", start_date="20150101", end_date="20500101", adjust="qfq")
    
    df = df.rename(columns={'æ—¥æœŸ': 'date', 'æ”¶ç›˜': 'close'})
    df['date'] = pd.to_datetime(df['date']).dt.strftime('%Y-%m-%d')
    df = df.sort_values('date')
    
    if LIMIT_DAYS: df = df.tail(LIMIT_DAYS)
    return df[['date', 'close']]

def get_margin_balance():
    """èèµ„èåˆ¸ä½™é¢ (ä¸Šäº¤æ‰€å†å²æ•°æ®)"""
    df = ak.stock_margin_sse(start_date='20100101', end_date='20501231')
    
    if df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    # æ—¥æœŸæ ¼å¼: 20251216
    result['date'] = pd.to_datetime(df['ä¿¡ç”¨äº¤æ˜“æ—¥æœŸ'], format='%Y%m%d').dt.strftime('%Y-%m-%d')
    # èèµ„ä½™é¢ (è½¬ä¸ºäº¿å…ƒ)
    result['margin_balance_yi'] = round(pd.to_numeric(df['èèµ„ä½™é¢'], errors='coerce') / 100000000, 2)
    # èèµ„èåˆ¸ä½™é¢ (è½¬ä¸ºäº¿å…ƒ)
    result['total_balance_yi'] = round(pd.to_numeric(df['èèµ„èåˆ¸ä½™é¢'], errors='coerce') / 100000000, 2)
    result = result.dropna()
    result = result.sort_values('date')
    
    if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
    return result

def get_shibor():
    """Shiboråˆ©ç‡ (éš”å¤œ/1å‘¨/1æœˆ)"""
    df = ak.macro_china_shibor_all()
    
    if df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    result['overnight'] = pd.to_numeric(df['O/N-å®šä»·'], errors='coerce')  # éš”å¤œ
    result['week_1'] = pd.to_numeric(df['1W-å®šä»·'], errors='coerce')      # 1å‘¨
    result['month_1'] = pd.to_numeric(df['1M-å®šä»·'], errors='coerce')     # 1æœˆ
    result = result.dropna()
    result = result.sort_values('date')
    
    if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
    return result

def get_bond_yield():
    """ä¸­ç¾å›½å€ºæ”¶ç›Šç‡"""
    df = ak.bond_zh_us_rate()
    
    if df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    result['cn_10y'] = pd.to_numeric(df['ä¸­å›½å›½å€ºæ”¶ç›Šç‡10å¹´'], errors='coerce')
    result['us_10y'] = pd.to_numeric(df['ç¾å›½å›½å€ºæ”¶ç›Šç‡10å¹´'], errors='coerce')
    # ä¸­ç¾åˆ©å·® = ä¸­å›½10å¹´ - ç¾å›½10å¹´
    result['spread'] = round(result['cn_10y'] - result['us_10y'], 4)
    
    # è¿‡æ»¤æ‰ä»»ä½•åŒ…å« NaN çš„è¡Œ (é¿å…å‰ç«¯æ˜¾ç¤ºé—®é¢˜)
    result = result.dropna(subset=['cn_10y', 'us_10y', 'spread'])
    result = result.sort_values('date')
    
    if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
    return result

def get_market_fund_flow():
    """å¸‚åœºèµ„é‡‘æµå‘ (ä¸»åŠ›/è¶…å¤§å•/å¤§å•å‡€æµå…¥)"""
    df = ak.stock_market_fund_flow()
    
    if df.empty:
        return pd.DataFrame()
    
    result = pd.DataFrame()
    result['date'] = pd.to_datetime(df['æ—¥æœŸ']).dt.strftime('%Y-%m-%d')
    # ä¸»åŠ›å‡€æµå…¥ (äº¿å…ƒ)
    result['main_net_yi'] = round(pd.to_numeric(df['ä¸»åŠ›å‡€æµå…¥-å‡€é¢'], errors='coerce') / 100000000, 2)
    # ä¸»åŠ›å‡€å æ¯” (%)
    result['main_pct'] = pd.to_numeric(df['ä¸»åŠ›å‡€æµå…¥-å‡€å æ¯”'], errors='coerce')
    # è¶…å¤§å•å‡€æµå…¥ (äº¿å…ƒ)
    result['super_net_yi'] = round(pd.to_numeric(df['è¶…å¤§å•å‡€æµå…¥-å‡€é¢'], errors='coerce') / 100000000, 2)
    result = result.dropna()
    result = result.sort_values('date')
    
    if LIMIT_DAYS: result = result.tail(LIMIT_DAYS)
    return result

# ================= ğŸ’¾ ç”Ÿæˆé€»è¾‘ =================

def load_existing_data():
    """åŠ è½½ç°æœ‰æ•°æ®æ–‡ä»¶"""
    if not os.path.exists(OUTPUT_PATH):
        return None
    try:
        with open(OUTPUT_PATH, 'r', encoding='utf-8') as f:
            content = f.read()
            # æå– JSON éƒ¨åˆ†
            start = content.find('{')
            end = content.rfind('}') + 1
            if start == -1 or end == 0:
                return None
            json_str = content[start:end]
            return json.loads(json_str)
    except Exception as e:
        print(f"âš ï¸ åŠ è½½ç°æœ‰æ•°æ®å¤±è´¥: {e}")
        return None

def merge_data(existing_list, new_list, date_key='date'):
    """åˆå¹¶æ•°æ®ï¼Œå»é‡å¹¶æŒ‰æ—¥æœŸæ’åº"""
    if not existing_list:
        return new_list
    if not new_list:
        return existing_list
    
    # ç”¨å­—å…¸å»é‡ï¼Œæ–°æ•°æ®è¦†ç›–æ—§æ•°æ®
    merged = {d[date_key]: d for d in existing_list}
    for d in new_list:
        merged[d[date_key]] = d
    
    # æŒ‰æ—¥æœŸæ’åº
    result = sorted(merged.values(), key=lambda x: x[date_key])
    
    # é™åˆ¶æ€»æ•°æ®é‡
    if LIMIT_DAYS and len(result) > LIMIT_DAYS:
        result = result[-LIMIT_DAYS:]
    
    return result

def generate_ts_file(data_map):
    print("\nğŸ’¾ æ­£åœ¨ç”Ÿæˆ TypeScript æ–‡ä»¶...")
    
    final_obj = {
        "meta": {
            "updated_at": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
            "desc": "Aè‚¡/æ¸¯è‚¡/èµ„é‡‘/æ±‡ç‡/ç¾è‚¡/èèµ„èåˆ¸/åˆ©ç‡/å›½å€º ç»¼åˆæ•°æ®"
        },
        "data": data_map
    }
    
    json_str = json.dumps(final_obj, ensure_ascii=False, indent=2)
    
    ts_content = f"""/**
 * è‚¡å¸‚å…¨ç»´åˆ†ææ•°æ®
 * è‡ªåŠ¨ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
 * æ³¨æ„: æ¸¯è‚¡è‹¥æ— æˆäº¤é¢(amount_yi)åˆ™ä¸º0, è¯·ä½¿ç”¨å—å‘èµ„é‡‘è¾…åŠ©åˆ¤æ–­
 */

export const MARKET_FULL = {json_str};
"""
    try:
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            f.write(ts_content)
        print(f"ğŸ‰ æˆåŠŸ! æ–‡ä»¶å·²ç”Ÿæˆåœ¨: {OUTPUT_PATH}")
    except Exception as e:
        print(f"âŒ æ–‡ä»¶å†™å…¥å¤±è´¥: {e}")

def fetch_full_data():
    """å…¨é‡è·å–æ‰€æœ‰æ•°æ®"""
    print("ğŸš€ å¼€å§‹è·å–å…¨çƒå¸‚åœºæ•°æ® (å…¨é‡æ¨¡å¼)...")
    print("-" * 40)
    
    # 1. æ ¸å¿ƒæ•°æ® (å¿…é¡»æˆåŠŸ)
    a_share = safe_fetch(get_a_share, "Aè‚¡å¤§ç›˜(æ²ªæ·±)")
    north = safe_fetch(get_hsgt_funds, "åŒ—å‘èµ„é‡‘", symbol="åŒ—å‘èµ„é‡‘")
    
    # 2. è¾…åŠ©æ•°æ® (å…è®¸å¶å°”å¤±è´¥ï¼Œå¤±è´¥ç»™ç©ºæ•°ç»„)
    hk_main = safe_fetch(get_hk_index_data, "æ’ç”ŸæŒ‡æ•°", symbol_em="HSI", symbol_sina="HSI", name_arg="æ’ç”ŸæŒ‡æ•°")
    hk_tech = safe_fetch(get_hk_index_data, "æ’ç”Ÿç§‘æŠ€", symbol_em="HSTECH", symbol_sina="HSTECH", name_arg="æ’ç”Ÿç§‘æŠ€")
    south = safe_fetch(get_hsgt_funds, "å—å‘èµ„é‡‘", symbol="å—å‘èµ„é‡‘")
    rate = safe_fetch(get_exchange_rate, "äººæ°‘å¸æ±‡ç‡")
    nasdaq = safe_fetch(get_nasdaq_etf, "çº³æ–¯è¾¾å…‹(QQQ)")
    
    # 3. æ–°å¢è¾…åŠ©æŒ‡æ ‡
    margin = safe_fetch(get_margin_balance, "èèµ„èåˆ¸(ä¸Šäº¤æ‰€)")
    shibor = safe_fetch(get_shibor, "Shiboråˆ©ç‡")
    bond = safe_fetch(get_bond_yield, "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡")
    fund_flow = safe_fetch(get_market_fund_flow, "å¸‚åœºèµ„é‡‘æµå‘")
    
    print("-" * 40)
    
    # 4. å®‰å…¨æ£€æŸ¥ï¼šåªæœ‰æ ¸å¿ƒæ•°æ®å­˜åœ¨æ‰ç”Ÿæˆæ–‡ä»¶
    if not a_share or not north:
        print("ğŸ›‘ ä¸¥é‡é”™è¯¯ï¼šAè‚¡æˆ–åŒ—å‘èµ„é‡‘æ•°æ®è·å–å¤±è´¥ï¼Œå–æ¶ˆç”Ÿæˆæ–‡ä»¶ã€‚")
        print("   è¯·æ£€æŸ¥ç½‘ç»œæˆ– akshare ç‰ˆæœ¬ (pip install --upgrade akshare)")
        sys.exit(1)
        
    return {
        "a_share": a_share,
        "hk_main": hk_main,
        "hk_tech": hk_tech,
        "north": north,
        "south": south,
        "rate": rate,
        "nasdaq": nasdaq,
        "margin": margin,
        "shibor": shibor,
        "bond": bond,
        "fund_flow": fund_flow
    }

def fetch_incremental_data(days=30):
    """å¢é‡è·å–æœ€è¿‘Nå¤©æ•°æ®ï¼Œå¹¶ä¸ç°æœ‰æ•°æ®åˆå¹¶"""
    print(f"ğŸš€ å¼€å§‹è·å–å…¨çƒå¸‚åœºæ•°æ® (å¢é‡æ¨¡å¼: æœ€è¿‘{days}å¤©)...")
    print("-" * 40)
    
    # åŠ è½½ç°æœ‰æ•°æ®
    existing = load_existing_data()
    if not existing:
        print("âš ï¸ æœªæ‰¾åˆ°ç°æœ‰æ•°æ®ï¼Œåˆ‡æ¢åˆ°å…¨é‡æ¨¡å¼...")
        return fetch_full_data()
    
    existing_data = existing.get('data', {})
    last_update = existing.get('meta', {}).get('updated_at', 'æœªçŸ¥')
    print(f"ğŸ“‚ å·²åŠ è½½ç°æœ‰æ•°æ® (ä¸Šæ¬¡æ›´æ–°: {last_update})")
    
    # ä¸´æ—¶ä¿®æ”¹ LIMIT_DAYS åªè·å–æœ€è¿‘çš„æ•°æ®
    global LIMIT_DAYS
    original_limit = LIMIT_DAYS
    LIMIT_DAYS = days
    
    try:
        # è·å–æ–°æ•°æ®
        a_share_new = safe_fetch(get_a_share, "Aè‚¡å¤§ç›˜(æ²ªæ·±)")
        north_new = safe_fetch(get_hsgt_funds, "åŒ—å‘èµ„é‡‘", symbol="åŒ—å‘èµ„é‡‘")
        hk_main_new = safe_fetch(get_hk_index_data, "æ’ç”ŸæŒ‡æ•°", symbol_em="HSI", symbol_sina="HSI", name_arg="æ’ç”ŸæŒ‡æ•°")
        hk_tech_new = safe_fetch(get_hk_index_data, "æ’ç”Ÿç§‘æŠ€", symbol_em="HSTECH", symbol_sina="HSTECH", name_arg="æ’ç”Ÿç§‘æŠ€")
        south_new = safe_fetch(get_hsgt_funds, "å—å‘èµ„é‡‘", symbol="å—å‘èµ„é‡‘")
        rate_new = safe_fetch(get_exchange_rate, "äººæ°‘å¸æ±‡ç‡")
        nasdaq_new = safe_fetch(get_nasdaq_etf, "çº³æ–¯è¾¾å…‹(QQQ)")
        margin_new = safe_fetch(get_margin_balance, "èèµ„èåˆ¸(ä¸Šäº¤æ‰€)")
        shibor_new = safe_fetch(get_shibor, "Shiboråˆ©ç‡")
        bond_new = safe_fetch(get_bond_yield, "ä¸­ç¾å›½å€ºæ”¶ç›Šç‡")
        fund_flow_new = safe_fetch(get_market_fund_flow, "å¸‚åœºèµ„é‡‘æµå‘")
    finally:
        LIMIT_DAYS = original_limit
    
    print("-" * 40)
    
    # æ ¸å¿ƒæ•°æ®æ£€æŸ¥
    if not a_share_new:
        print("ğŸ›‘ ä¸¥é‡é”™è¯¯ï¼šAè‚¡æ•°æ®è·å–å¤±è´¥ï¼Œå–æ¶ˆæ›´æ–°ã€‚")
        sys.exit(1)
    
    # åˆå¹¶æ•°æ®
    print("ğŸ”„ æ­£åœ¨åˆå¹¶æ•°æ®...")
    
    return {
        "a_share": merge_data(existing_data.get('a_share', []), a_share_new),
        "hk_main": merge_data(existing_data.get('hk_main', []), hk_main_new),
        "hk_tech": merge_data(existing_data.get('hk_tech', []), hk_tech_new),
        "north": merge_data(existing_data.get('north', []), north_new),
        "south": merge_data(existing_data.get('south', []), south_new),
        "rate": merge_data(existing_data.get('rate', []), rate_new),
        "nasdaq": merge_data(existing_data.get('nasdaq', []), nasdaq_new),
        "margin": merge_data(existing_data.get('margin', []), margin_new),
        "shibor": merge_data(existing_data.get('shibor', []), shibor_new),
        "bond": merge_data(existing_data.get('bond', []), bond_new),
        "fund_flow": merge_data(existing_data.get('fund_flow', []), fund_flow_new),
    }

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description='è‚¡å¸‚æ•°æ®è·å–å·¥å…·')
    parser.add_argument('--mode', choices=['full', 'incremental'], default='incremental',
                        help='è·å–æ¨¡å¼: full=å…¨é‡, incremental=å¢é‡ (é»˜è®¤: incremental)')
    parser.add_argument('--days', type=int, default=30,
                        help='å¢é‡æ¨¡å¼ä¸‹è·å–æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ® (é»˜è®¤: 30)')
    args = parser.parse_args()
    
    if args.mode == 'full':
        data_map = fetch_full_data()
    else:
        data_map = fetch_incremental_data(days=args.days)
    
    generate_ts_file(data_map)